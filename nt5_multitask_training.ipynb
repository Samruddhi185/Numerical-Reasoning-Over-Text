{"cells":[{"cell_type":"markdown","metadata":{"id":"MYi0HlUHzyZZ"},"source":["# Fine-Tuning on NT5 Multitask Training\n","Authors:   \n","Aditya Todi, atodi@cs.stonybrook.edu  \n","Omkar Kanade, okanade@cs.stonybrook.edu  \n","Samruddhi Patil, sampatil@cs.stonybrook.edu"]},{"cell_type":"markdown","metadata":{"id":"LFQb1V1jz8N6"},"source":["## Setup\n","The section includes all the global parameters and codes to set up the environment for the NT5 training pipeline."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"g_i7eoklU6KI","executionInfo":{"status":"ok","timestamp":1670470149061,"user_tz":300,"elapsed":824,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}}},"outputs":[],"source":["if 'colab' in str(get_ipython()):\n","    import google.colab as colab\n","    from IPython.display import clear_output\n","\n","    colab.auth.authenticate_user()\n","    colab.drive.mount('/content/gdrive') # mount google drive\n","\n","    !pip install tensorflow-text\n","    !pip install transformers\n","    !pip install datasets\n","    !pip install tqdm\n","    !pip install --pre allennlp-models\n","\n","    clear_output() "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13433,"status":"ok","timestamp":1670470213472,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"},"user_tz":300},"id":"7IQfnAOUTleu","outputId":"505dfe89-f9e2-4843-80ca-0d94dd0000a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 2.11.0\n"]}],"source":["# ml libraries\n","from __future__ import print_function\n","\n","import tensorflow as tf\n","import tensorflow_text as tf_text\n","import tensorflow.keras as keras\n","import tensorflow.keras.backend as K\n","import tensorflow_datasets as tfds\n","import transformers\n","import datasets # https://huggingface.co/docs/datasets/\n","\n","# for allennlp, if you did a pip install on colab, restart the runtime\n","from allennlp.common.testing import (\n","                                AllenNlpTestCase,\n","                                global_distributed_metric,\n","                                run_distributed_test)\n","from allennlp_models.rc.metrics import DropEmAndF1\n","\n","# data processing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from google.cloud import storage as gcs\n","\n","# other libraries\n","import os\n","import json\n","import functools\n","import time\n","import math\n","import warnings\n","import string\n","import re\n","import argparse\n","import pickle\n","from collections import Counter\n","from datetime import datetime\n","from IPython.display import clear_output\n","\n","# plot libs\n","import matplotlib.pyplot as plt\n","\n","print(f'TensorFlow {tf.__version__}')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"A8Cue-K52LC-","colab":{"base_uri":"https://localhost:8080/","height":235,"referenced_widgets":["3896a19c564440e798220672af42c188","d22f93005e74465a98f3c11c20fac04d","8f701f189ff44010b3a9c5134b485f70","a34330e52b2345d0875abf3468ca2171","4b4a7bfcefff44f3913f8a27917fec01","eda89e0f38ed4bf49e67603b4aabcfba","53c69b5ed851406aa93093a8f2e56d58","054abbc918034123933a9ceb12e2fe43","b285406a23384e4388e327ccb9e18325","46fc99eb6f6a4a14973c3167dc212c2f","3c1280c6e6e64acc9b61eadfe18ae2d6","a4a148ffa5c94f22969f7292c26dbc61","8e6c0163b6b54389b58174d33ddada0f","81c31392c7cd4e98969c86773d21cf28","b339df998e2c4428bf6ebd0b0255bf4f","3bcb771590b14513acae1d3096dfef37","0e6cc33e89784d83b131652ede153113","ddfdbf0f6a59459eaa1aaee944282e32","d10d6ac40ce44972b5369e2d37c53425","183f88b354b541418fb11ee9c6f6c7ea","90af3e4ddc664836a2b37e7e51fde94b","fada5a52ea8948e08516257349239171","a28160e8c9184cf6a3b55a9b27e94bd5","5fc6f032d8384509824cf14908ca7c4c","fd69064f923f4c0280e746908932c3e5","af38ecbc455e4a11b1b88dcf9e03e955","414e9ee2c704475ab93e19284c18fa91","57068558918941f8b7b3d45168fe3fa3","c36cbb7d4f23407c9fc05977897327da","878cf441b2654d3eb472fc74466e1adf","60d75b20a63849379aad2923a813684c","e590a40cd0d340bb8fba739cdffb7dbb","9b73f5b62bf44caf808f87b4dce65f99"]},"executionInfo":{"status":"ok","timestamp":1670470302043,"user_tz":300,"elapsed":5805,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}},"outputId":"0e27ec52-37f2-402c-a623-5b0800629844"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3896a19c564440e798220672af42c188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4a148ffa5c94f22969f7292c26dbc61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28160e8c9184cf6a3b55a9b27e94bd5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}],"source":["PROCESSOR = 'GPU'\n","EVALUATE_DEV = True\n","EVALUATE_TEST = False\n","\n","# ------------------------------------------------------------------------------\n","# SEMSITIVE PRIVATE INFO\n","\n","# path to repo on gdrive\n","# gdrive is used to save/load csv (e.g. performance evaluation reports) and model files \n","GDRIVE_REPO_PATH='/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5'\n","\n","\n","# gcp storage paths\n","DROP_PATH_GCP = '/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/datasets'\n","\n","# token for wandb, training results tracker\n","WAND_LOGIN_TOKEN = ''\n","\n","# ------------------------------------------------------------------------------\n","# T5 NONSTOP TRAINING CONFIGS\n","\n","# \"t5-small\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json\"\n","# \"t5-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json\"\n","# \"t5-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-large-config.json\"\n","# \"t5-3b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-3b-config.json\"\n","# \"t5-11b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-11b-config.json\"\n","T5_MODEL = 't5-small'\n","EPOCHS = 2\n","\n","# ------------------------------------------------------------------------------\n","# T5 CONTINUOUS TRAINING CONFIGS\n","# NOTE: Do NOT confuse \"continuous training\" with \"stage training.\" \"Continuous \n","# training\" in this notebook refers to the scenarion where the full traning schedule \n","# (e.g. 60 epochs) for the SAME dataset is broken in to multiple sub trainng schedules \n","# (e.g. two 30-epochs training). \"Stage training\" refers to a new training schedule\n","# thatfor a new dataset, although the training can be on top of a model that has been\n","# trained on other datasets. For example, each stage of the following training schedule\n","# is a stage: NUMERICAL DATASET -> TEXTUAL DATASET -> SQUAD -> DROP. \"Continous\n","# training\" can take place when the 60-epoch training schedule on NUMERICAL DATASET is \n","# broken into two 30-epoch training schedules.\n","\n","# doit: set to true ONLY IF continue training for the SAME dataset\n","# epoch_total defines the total number of epochs for the entire training schedule\n","# epoch_start defines the starting # of epoch for the current training\n","# epoch_end defines the ending # of epoch for the current training\n","EPOCHS_CONTINUE = {'doit': False, \n","                   'epoch_total': 60,\n","                   'epoch_start': 16,\n","                   'epoch_end': 30}\n","\n","# ------------------------------------------------------------------------------\n","# DATASET CONFIGS\n","\n","# MUSIQUE DATASET\n","MUSIQUE_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'musique/musique_train.tfrecord')\n","MUSIQUE_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'musique/musique_dev.tfrecord')\n","MUSIQUE_TRAIN_EXAMPLE_COUNT = 39876\n","MUSIQUE_DEV_EXAMPLE_COUNT = 4834\n","MUSIQUE_TRAIN_JSON = os.path.join(DROP_PATH_GCP, 'musique/musique_train.json')\n","MUSIQUE_DEV_JSON = os.path.join(DROP_PATH_GCP, 'musique/musique_dev.json')\n","\n","# DROP DATASET  \n","DROP_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_train_v4_77400.tfrecord')\n","DROP_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev_v4_9536.tfrecord')\n","DROP_TRAIN_EXAMPLE_COUNT = 77400\n","DROP_DEV_EXAMPLE_COUNT = 9536\n","DROP_DEV_JSON = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev.json')\n","DROP_TEST_JSON = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_test_questions.json')\n","\n","# DROP CATEGORY DATASET\n","DROP_CATEGORY_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_train_v4_cat_77400.tfrecord')\n","DROP_CATEGORY_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev_v4_cat_9536.tfrecord')\n","DROP_CATEGORY_TRAIN_EXAMPLE_COUNT = 77400\n","DROP_CATEGORY_DEV_EXAMPLE_COUNT = 9536\n","\n","# NUMERICAL DATASET\n","SYN_NUM_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'numeric/numeric_train_data_parsed_v2_990000.tfrecord')\n","SYN_NUM_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'numeric/numeric_dev_data_parsed_v2_9996.tfrecord')\n","SYN_NUM_TRAIN_EXAMPLE_COUNT = 990000\n","SYN_NUM_DEV_EXAMPLE_COUNT = 9996\n","\n","SQUAD_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'squad/squad1.1_train_data_parsed_v3_87599.tfrecord')\n","SQUAD_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'squad/squad1.1_dev_data_parsed_v3_10570.tfrecord')\n","SQUAD_TRAIN_EXAMPLE_COUNT = 87599\n","SQUAD_DEV_EXAMPLE_COUNT = 10570\n","\n","# TEXTUAL DATASET\n","SYN_TXT_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'textual/textual_train_data_parsed_v2_2523192.tfrecord')\n","SYN_TXT_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'textual/textual_dev_data_parsed_v2_10000.tfrecord')\n","SYN_TXT_TRAIN_EXAMPLE_COUNT = 2523192\n","SYN_TXT_DEV_EXAMPLE_COUNT = 10000\n","\n","# ------------------------------------------------------------------------------\n","# TRAINING CONFIGS\n","\n","# BASIC SETUP\n","BATCH_SIZE = 32\n","ENCODER_MAX_LEN = 512 # must be consistent with configs used to build TFRecords\n","DECODER_MAX_LEN = 54 # must be consistent with configs used to build TFRecords\n","TOKENIZER = transformers.AutoTokenizer.from_pretrained(T5_MODEL)\n","special_tokens_dict = {'additional_special_tokens': ['0','1','2','3', '4', '5', '6', '7', '8', '9', '<ss>', '<sv>']}\n","num_added_toks = TOKENIZER.add_special_tokens(special_tokens_dict)\n","\n","# DATASET MIXTURE CONFIGS\n","IS_TRAIN_DS_MIXTURE = False\n","MIXTURE_TEMP = 1\n","MIXTURE_MAX = None\n","MIXTURE_SCALE = 1\n","\n","# TRAINING STEPS\n","if IS_TRAIN_DS_MIXTURE:\n","    # mixture\n","    VALID_TOTAL_EXAMPLE_COUNT = SYN_TXT_DEV_EXAMPLE_COUNT\n","    VALID_STEPS = math.ceil(VALID_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)\n","    TRAIN_STEPS = None # train steps will be updated after ds is loaded with the predefined tempature\n","else:\n","    # single ds\n","    TRAIN_TOTAL_EXAMPLE_COUNT = DROP_TRAIN_EXAMPLE_COUNT\n","    VALID_TOTAL_EXAMPLE_COUNT = DROP_DEV_EXAMPLE_COUNT\n","    TRAIN_STEPS = math.ceil(TRAIN_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)\n","    VALID_STEPS = math.ceil(VALID_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)    \n","\n","# ------------------------------------------------------------------------------\n","# LARNING RATE CONFIGS\n","\n","LR_DO_WARMUP_DECAY = True\n","LR_CONSTANT = 0.001 # constant lr will be used if LR_DO_WARMUP_DECAY is set to False\n","LR_WARMUP_START = 1e-8 # lr for the 1st epoch\n","LR_WARMUP_END = 1e-4\n","LR_MIN = LR_WARMUP_START\n","LR_DECAY_RATE_LINEAR = 0.001\n","if EPOCHS >= 10:\n","    # allocate 10% of training steps to warmup\n","    WARMP_UP_EPOCHS = EPOCHS / 10 \n","else:\n","    # just for testing\n","    WARMP_UP_EPOCHS = 1\n","\n","# ------------------------------------------------------------------------------\n","# MODEL SAVING CONFIGS\n","\n","SAVE_TRAINED_MODEL = True\n","\n","SAVE_MODEL_WEIGHTS_ONLY = True\n","SAVE_MODEL_CHECKPOINTS_LOCAL = True\n","SAVE_MODEL_CHECKPOINTS_WANDB = False\n","SAVE_BEST_MODEL_ONLY = True\n","TENSORBOARD_LOG_PATH = f'{GDRIVE_REPO_PATH}/logs'\n","MODEL_SAVE_PATH = f'{GDRIVE_REPO_PATH}/models'\n","SHOW_TENSORBOARD = False\n","SHOW_WANDB = False\n","WANDB_PROJECT_NAME = 't5-numerical-reasoning'"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1670470925492,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"},"user_tz":300},"id":"tKp4tsQP2zjp","outputId":"2accefb9-d256-4f3c-adf3-546d6cb69689"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using default strategy for CPU/GPU...\n","1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["# ref: https://www.tensorflow.org/guide/tpu\n","if PROCESSOR == \"TPU\":\n","    print(\"connecting to TPU...\")\n","    try:\n","        # 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU: ', tpu.get_master())\n","    except ValueError:\n","        print(\"Error: Unable to connect to TPU...\")\n","        tpu = None\n","\n","    if tpu:\n","        try:\n","            print(\"Initializing TPU...\")\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.TPUStrategy(tpu) # tf 2.3.x\n","            print(\"TPU initialized!\")\n","        except:\n","            print(\"Error: Failed to initialize TPU...\")\n","    else:\n","        PROCESSOR = \"GPU\"\n","\n","if PROCESSOR != \"TPU\":\n","    print(\"Using default strategy for CPU/GPU...\")\n","    strategy = tf.distribute.get_strategy()\n","\n","if PROCESSOR == \"GPU\":\n","    # ref: https://tinyurl.com/yxddsxxq\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            # memory growth needs to be the same across GPUs\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","        except RuntimeError as e:\n","            # memory growth must be set before GPUs have been initialized\n","            print(e)"]},{"cell_type":"markdown","metadata":{"id":"lpYS2xVMzUob"},"source":["## Dataset Prep\n","The section provides functions and codes to prepare the datasets for training."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"FgemIZLhptrl","executionInfo":{"status":"ok","timestamp":1670470927625,"user_tz":300,"elapsed":343,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}}},"outputs":[],"source":["def prep_tfrec_ds(\n","            tfrec_path: str, \n","            batch_size: int = BATCH_SIZE,\n","            repeat: bool = True,\n","            shuffle: bool = True,\n","            processor: str = PROCESSOR,\n","            encoder_max_len: int = ENCODER_MAX_LEN,\n","            decoder_max_len: int = DECODER_MAX_LEN,\n","            mode: str = 'train') -> tf.data.TFRecordDataset:\n","\n","    if mode == 'train':\n","        features_description = {\n","            'input_ids': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64),\n","            'attention_mask': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64), \n","            'labels': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64),\n","            'decoder_attention_mask': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64)\n","        }\n","    else:\n","        features_description = {\n","            'input_ids': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64),\n","            'attention_mask': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64), \n","            'labels': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64),\n","            'decoder_attention_mask': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64),\n","            'answer_type': tf.io.FixedLenFeature([1], tf.string),\n","            'query_id': tf.io.FixedLenFeature([1], tf.string),\n","            'validated_answers': tf.io.FixedLenFeature([1], tf.string)\n","        }\n","\n","    ds = tf.data.TFRecordDataset(\n","                        tfrec_path, \n","                        num_parallel_reads=tf.data.experimental.AUTOTUNE)\n","    ds = ds.map(lambda batch_seralized: tf.io.parse_example(\n","                                                batch_seralized, \n","                                                features_description),\n","                                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    if shuffle: \n","        ds = ds.shuffle(buffer_size=1024) # 1024 to optimize TPU performance\n","    ds = ds.repeat(-1) if repeat else ds.repeat(1)\n","    ds = ds.batch(batch_size)\n","\n","    # From tf doc (https://tinyurl.com/yavczqkr):\n","    # Most dataset input pipelines should end with a call to prefetch. This allows \n","    # later elements to be prepared while the current element is being processed. This \n","    # often improves latency and throughput, at the cost of using additional memory to \n","    # store prefetched elements.\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","    # https://tinyurl.com/yao4obsb\n","    # A single Cloud TPU device consists of four chips, each of which has two TPU cores. \n","    # Therefore, for efficient utilization of Cloud TPU, a program should make use of \n","    # each of the eight cores.\n","    #\n","    # https://tinyurl.com/y99kjyh5\n","    # Model processing performance\n","    # For optimum memory usage, use the largest batch size that will fit in memory. \n","    # Each TPU core uses a 128 x 128 memory cell matrix for processing. In general, \n","    # your batch sized should be evenly divisible by 128 to most effectively use the TPU memory.\n","    #\n","    # https://tinyurl.com/yawn2acn\n","    # Batch Size Too Small\n","    # The batch size of any model should always be at least 64 (8 per TPU core) \n","    # because TPU always pads the tensors to this size. The ideal batch size when \n","    # training on the TPU is 1024 (128 per TPU core), since this eliminates inefficiencies \n","    # related to memory transfer and padding.\n","    #\n","    # https://tinyurl.com/y9nojpa2\n","    # Minimal requirement: A multiple of 8!\n","    if processor == 'TPU':\n","        if batch_size < 64:\n","            # better\n","            print('Warning: Batch size {} is smaller than 64...'.format(batch_size))\n","        if batch_size % 8 > 0:\n","            # min requirement\n","            print('Warning: Batch size {} is not a multiple of 8...'.format(batch_size))\n","        \n","    return ds\n","\n","def prep_multitask_tfrec_ds(\n","                    tfrec_paths: list, # path is now a list object\n","                    tfrec_example_counts: list = [],\n","                    batch_size: int = BATCH_SIZE,\n","                    repeat: bool = True,\n","                    shuffle: bool = True,\n","                    processor: str = PROCESSOR,\n","                    encoder_max_len: int = ENCODER_MAX_LEN,\n","                    decoder_max_len: int = DECODER_MAX_LEN):\n","\n","    datasets = []\n","    dataset_lengths = []\n","    if len(tfrec_example_counts) == len(tfrec_paths):\n","        dataset_lengths = tfrec_example_counts\n","    else:\n","        dataset_lengths = []\n","\n","    # iterate datasets to:\n","    # 1. grab length from file name, xyz_1234.tfrecord -> 1234\n","    # 2. read in to list\n","    for i, path in enumerate(tfrec_paths):\n","        file_name = os.path.basename(path)\n","\n","        # compute & store number of examples in tfrec\n","        if len(tfrec_example_counts) != len(tfrec_paths):\n","            length = int(re.search(r'_(\\d+)\\.', file_name).group(1))\n","            dataset_lengths.append(length)\n","\n","        # prep each individual ds\n","        ds = tf.data.TFRecordDataset(\n","                            path, \n","                            num_parallel_reads=tf.data.experimental.AUTOTUNE)\n","        if shuffle: \n","            ds = ds.shuffle(buffer_size=1024)\n","        datasets.append(ds.repeat())\n","        \n","    # calculate sampling weights\n","    print(\"Dataset lengths:\", dataset_lengths)\n","    dataset_weights = temperature_to_weights(dataset_lengths)\n","    print(\"Ratio:\", dataset_weights)\n","    # sample from datasets for a mixture dataset\n","    ds = tf.data.experimental.sample_from_datasets(\n","                                                datasets, \n","                                                weights=dataset_weights)\n","\n","    # prep consolidated ds\n","    features_description = {\n","        'input_ids': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64),\n","        'attention_mask': tf.io.FixedLenFeature([ENCODER_MAX_LEN], tf.int64), \n","        'labels': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64),\n","        'decoder_attention_mask': tf.io.FixedLenFeature([DECODER_MAX_LEN], tf.int64),\n","    }\n","    ds = ds.map(lambda batch_seralized: tf.io.parse_example(\n","                                                batch_seralized, \n","                                                features_description),\n","                                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","    ds = ds.batch(batch_size)\n","    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n","    if processor == 'TPU':\n","        if batch_size < 64:\n","            # better\n","            print('Warning: Batch size {} is smaller than 64...'.format(batch_size))\n","        if batch_size % 8 > 0:\n","            # min requirement\n","            print('Warning: Batch size {} is not a multiple of 8...'.format(batch_size))\n","    \n","    min_size_index = np.argmin(dataset_lengths)\n","    min_size = dataset_lengths[min_size_index]\n","    min_size_sampling_weight = dataset_weights[min_size_index]\n","    scale = float(min_size) / min_size_sampling_weight\n","    max_ds_size = [scale * i for i in dataset_weights]\n","    print(\"Max sampled sizes:\", max_ds_size)\n","    \n","    return ds, max_ds_size\n","\n","def temperature_to_weights(\n","            dataset_lengths: list, \n","            temperature: float = MIXTURE_TEMP, \n","            maximum: bool = MIXTURE_MAX, \n","            scale: float = MIXTURE_SCALE) -> list:\n","    '''Calculate renormalized mixing rates\n","       this is the rates at which the datasets are sampled\n","    '''\n","    mixing_rates = []\n","    for length in dataset_lengths:\n","        rate = length * scale\n","        if maximum:\n","            rate = min(rate, maximum)\n","        if temperature != 1.0:\n","            rate = rate ** (1.0/temperature)\n","        mixing_rates.append(rate)\n","    mixing_rates = [float(rate)/sum(mixing_rates) for rate in mixing_rates]\n","    return mixing_rates"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670470928740,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"},"user_tz":300},"id":"u9OPNVSz9oo6","outputId":"b3f65294-cf63-4cf0-ab54-cea9c98abd56"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From <ipython-input-18-e05bd7699233>:119: sample_from_datasets_v2 (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.sample_from_datasets(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]},{"output_type":"stream","name":"stdout","text":["Dataset lengths: [39876]\n","Ratio: [1.0]\n","Max sampled sizes: [39876.0]\n","Train Steps: 2419, Valid Steps: 298\n"]}],"source":["if IS_TRAIN_DS_MIXTURE:\n","    # load/prep multitasking ds\n","    train_ds, max_ds_size = prep_multitask_tfrec_ds([DROP_TRAIN_TFREC, DROP_CATEGORY_TRAIN_TFREC])\n","    val_ds, max_ds_valid_size = prep_multitask_tfrec_ds([DROP_DEV_TFREC, DROP_CATEGORY_DEV_TFREC])\n","\n","    # update the global constants\n","    TRAIN_STEPS = math.ceil(int(sum(max_ds_size)) / BATCH_SIZE)\n","    VALID_STEPS = math.ceil(int(sum(max_ds_valid_size)) / BATCH_SIZE)\n","\n","else:\n","    # load/prep a single ds\n","    train_ds, max_ds_size = prep_multitask_tfrec_ds(\n","                                tfrec_paths=[MUSIQUE_TRAIN_TFREC],\n","                                tfrec_example_counts=[MUSIQUE_TRAIN_EXAMPLE_COUNT])\n","    val_ds = prep_tfrec_ds(MUSIQUE_DEV_TFREC)\n","\n","print(f'Train Steps: {TRAIN_STEPS}, Valid Steps: {VALID_STEPS}')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5540,"status":"ok","timestamp":1670470935696,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"},"user_tz":300},"id":"x9bL5iBjRDyS","outputId":"6d309592-2a21-48c7-dc60-a965ef5e8731"},"outputs":[{"output_type":"stream","name":"stdout","text":["# of examples in /content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/datasets/musique/musique_train.tfrecord: 19938\n","DROP_TRAIN_EXAMPLE_COUNT = 39876\n","\n","# of examples in /content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/datasets/musique/musique_dev.tfrecord: 2417\n","DROP_DEV_EXAMPLE_COUNT = 4834\n"]}],"source":["# set to true to print example counts for training and dev sets\n","PRINT_EXAMPLE_COUNT = True\n","\n","if PRINT_EXAMPLE_COUNT:\n","    def count_examples_in_tfrec(tfrec_path: str) -> int:\n","        return sum(1 for _ in tf.data.TFRecordDataset(tfrec_path))\n","\n","    print(f'# of examples in {MUSIQUE_TRAIN_TFREC}: {count_examples_in_tfrec(MUSIQUE_TRAIN_TFREC)}')\n","    print(f'DROP_TRAIN_EXAMPLE_COUNT = {MUSIQUE_TRAIN_EXAMPLE_COUNT}')\n","    print('')\n","    print(f'# of examples in {MUSIQUE_DEV_TFREC}: {count_examples_in_tfrec(MUSIQUE_DEV_TFREC)}')\n","    print(f'DROP_DEV_EXAMPLE_COUNT = {MUSIQUE_DEV_EXAMPLE_COUNT}')"]},{"cell_type":"markdown","metadata":{"id":"4t6C6HmUzLOW"},"source":["## Training\n","In this section, we build the pipeline for training. "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"SpS-qUAIzkLh","executionInfo":{"status":"ok","timestamp":1670471048378,"user_tz":300,"elapsed":820,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}}},"outputs":[],"source":["class DROPBaseT5(transformers.TFT5ForConditionalGeneration):\n","    def __init__(self, *args, log_dir: str = None, cache_dir: str = None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_tracker= tf.keras.metrics.Mean(name='loss')\n","\n","    # Notes from doc:\n","    # When you need to customize what fit() does, you should override the training \n","    # step function of the Model class. This is the function that is called by fit() \n","    # for every batch of data. You will then be able to call fit() as usual -- and \n","    # it will be running your own learning algorithm.\n","    @tf.function\n","    def train_step(self, data: datasets.Dataset) -> dict:\n","        # required for eager execution when customzing the the training loops\n","        with tf.GradientTape() as tape:\n","            # forward pass; equivalent of pushing the input x through the entire \n","            # neural network for a prediction\n","            # Note:\n","            # \"self\" is a reference to TFT5ForConditionalGeneration, which is a \n","            # subclass of keras.Model, which returns a reference to a function.\n","            # https://tinyurl.com/yx9qvmyf\n","            # https://keras.io/guides/customizing_what_happens_in_fit/\n","            # https://huggingface.co/transformers/model_doc/t5.html#tft5forconditionalgeneration\n","            # outputs = self(data, training=True) \n","            print(data[\"input_ids\"])\n","            outputs = super().call(\n","                        input_ids=data[\"input_ids\"],\n","                        labels=data[\"labels\"],\n","                        attention_mask=data[\"attention_mask\"],\n","                        decoder_attention_mask=data[\"decoder_attention_mask\"],\n","                        training=True)\n","        \n","            # record the gradient\n","            # output of hugging face is a tuple: (outputs.loss, outputs.logits)\n","            # https://huggingface.co/transformers/main_classes/output.html \n","            loss = tf.reduce_mean(outputs[0])\n","            grads = tape.gradient(loss, self.trainable_variables)\n","        \n","        # optimizer as defined through Keras' API when compiling the model\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n","        \n","        # track metrics\n","        y = tf.reshape(data[\"labels\"], [-1, 1])\n","        y_pred_logits = outputs[1]\n","        # lr = self.optimizer._decayed_lr(tf.float32)\n","        self.loss_tracker.update_state(loss)        \n","        self.compiled_metrics.update_state(data[\"labels\"], y_pred_logits)\n","        metrics = {m.name: m.result() for m in self.metrics}\n","        # metrics.update({'lr': lr})\n","        metrics.update({'loss': loss})\n","        \n","        return metrics\n","\n","    @tf.function\n","    def test_step(self, data: datasets.Dataset) -> dict:\n","        outputs = self(data, training=True) \n","        y_pred_logits = outputs[1]\n","        loss = outputs[0]\n","\n","        # compute loss\n","        loss = tf.reduce_mean(loss)\n","        self.loss_tracker.update_state(loss)\n","\n","        # update metrics\n","        y = tf.reshape(data[\"labels\"], [-1, 1])\n","        self.compiled_metrics.update_state(y, y_pred_logits)\n","        metrics = {m.name: m.result() for m in self.metrics}\n","        metrics.update({'loss': loss})\n","\n","        return metrics\n","    \n","    @tf.function\n","    def reset_f1(self) -> dict:\n","        print('Reset F1...')\n","\n","class LRScheduler(keras.callbacks.Callback):\n","    \"\"\"Performing custom learning rate scheduling by extending Keras' Callback.\n","    \"\"\"\n","\n","    def __init__(\n","            self, \n","            warmup_batches      : int = TRAIN_STEPS * WARMP_UP_EPOCHS, \n","            lr_warmup_start     : float = LR_WARMUP_START, \n","            lr_warmup_end       : float = LR_WARMUP_END, \n","            lr_min              : int = LR_MIN,\n","            decay_rate          : float = LR_DECAY_RATE_LINEAR,\n","            verbose             : int = 1):\n","        super(LRScheduler, self).__init__()\n","\n","        # warm-up\n","        self.__warmup_batches = warmup_batches\n","        self.__lr_warmup_start = lr_warmup_start\n","        self.__lr_warmup_end = lr_warmup_end\n","        self.__lr_warmup_increment = (self.__lr_warmup_end - self.__lr_warmup_start) / self.__warmup_batches\n","        self.__is_warmup = True\n","\n","        # decay\n","        self.__decay_rate = decay_rate\n","        self.__lr_min = lr_min\n","\n","        # other properties\n","        self.__verbose = verbose\n","        self.__batch_count = 0\n","        self.__lr_warmup_arr = [] # by training step\n","        self.__lr_epoch_arr = [] # by training epoch\n","        \n","        self.__lr = 0\n","        self.__epoch = 0\n","        self.__warmup_epoch_last = 0 # epoch number where warmup ends\n","\n","    def on_batch_begin(self, batch, logs=None) -> None:\n","        if self.__is_warmup:\n","            if self.__batch_count <= self.__warmup_batches: \n","                self.__lr = self.__batch_count * self.__lr_warmup_increment + self.__lr_warmup_start\n","                K.set_value(self.model.optimizer.lr, self.__lr)\n","                self.__lr_warmup_arr.append(self.__lr)\n","                self.__batch_count  += 1\n","\n","                if self.__verbose > 0:\n","                    print(f'\\nWarm-up LR {self.__lr} at batch {self.__batch_count}...')                \n","            \n","    def on_batch_end(self, batch, logs=None) -> None:\n","        if self.__is_warmup:\n","            # end of warmup\n","            if self.__batch_count > self.__warmup_batches: \n","                self.__warmup_epoch_last = self.__epoch\n","                self.__is_warmup = False\n","\n","    def on_epoch_begin(self, epoch, logs=None) -> None:\n","        self.__epoch = epoch\n","        if self.__is_warmup:\n","            # hard code the lr calculation because on_batch_end for the first\n","            # batch of the epoch happens right after on_epoch_begin\n","            lr = self.__batch_count * self.__lr_warmup_increment + self.__lr_warmup_start    \n","            self.__lr_epoch_arr.append(lr)\n","            return\n","        \n","        self.__lr = K.get_value(self.model.optimizer.lr)\n","        if self.__lr <= self.__lr_min:\n","            K.set_value(self.model.optimizer.lr, self.__lr)\n","            self.__lr_epoch_arr.append(K.get_value(self.model.optimizer.lr))\n","            return\n","\n","        lr_new = self.__lr * 1 / (1 + self.__decay_rate * (epoch - self.__warmup_epoch_last))\n","        K.set_value(self.model.optimizer.lr, lr_new)\n","        self.__lr = K.get_value(self.model.optimizer.lr) # pull lr from optimizer to confirm\n","        self.__lr_epoch_arr.append(self.__lr)\n","\n","    def simulate_lr(\n","            self, \n","            steps_simulation: int = 1000,\n","            steps_per_epoch: int = TRAIN_STEPS,\n","            plot: bool = True) -> list:\n","        # hard code a model for simulation\n","        # note: self.model is accessible through tf in production\n","        self.model = DROPBaseT5.from_pretrained(T5_MODEL)\n","        self.model.compile(optimizer=keras.optimizers.Adam())\n","\n","        # simulate training\n","        for global_step in range(steps_simulation):\n","            batch_n = global_step % steps_per_epoch\n","            if batch_n == 0:\n","                self.on_epoch_begin(global_step // steps_per_epoch)\n","            self.on_batch_begin(batch_n)\n","            self.on_batch_end(batch_n)\n","\n","        if plot:\n","            # plot warmup lr\n","            x = range(1, len(self.__lr_warmup_arr) + 1)\n","            print('')\n","            print(f'Steps per epoch: {steps_per_epoch}')\n","            fig, ax = plt.subplots(figsize=(15, 6))\n","            ax.set_title(f'LR Warmup Schedule ({self.__warmup_batches:.0f} warm-up batches)', fontsize=14, pad=11)\n","            ax.set_ylabel('Learning Rate')\n","            ax.set_xlabel('Batch Step')\n","            ax.plot(x, self.__lr_warmup_arr)\n","            plt.show()\n","\n","            # plot epoch lr\n","            x = range(1, len(self.__lr_epoch_arr) + 1)\n","            print('')\n","            fig, ax = plt.subplots(figsize=(15, 6))\n","            ax.set_title(f'LR Epoch Schedule', fontsize=14, pad=11)\n","            ax.set_ylabel('Learning Rate')\n","            ax.set_xlabel('Epoch')\n","            ax.plot(x, self.__lr_epoch_arr)\n","            print(f'Ending LR: {self.__lr}')\n","            plt.show()\n","\n","        return self.__lr_epoch_arr\n","\n","class LRSimpleScheduler(keras.callbacks.Callback):\n","    \"\"\"The scheduler takes in a list of learning rates, and feed each learning\n","    rate to the model at the beginning of an epoch. If the number of epoch is larger\n","    than the length of the supplied learning rate list, the last item in the list will\n","    be repeatedly fed to the model.\n","    \"\"\"\n","    def __init__(self, learning_rates: list) -> None:\n","        self.__lr_schedule = learning_rates\n","        self.__lr_actual = []\n","            \n","    def on_epoch_begin(self, epoch, logs=None) -> None:\n","        if epoch < len(self.__lr_schedule):\n","            K.set_value(self.model.optimizer.lr, self.__lr_schedule[epoch])\n","        else:\n","            i_last = len(self.__lr_schedule) - 1\n","            K.set_value(self.model.optimizer.lr, self.__lr_schedule[i_last])\n","        \n","        lr = K.get_value(self.model.optimizer.lr)\n","        self.__lr_actual.append(lr)\n","    \n","    def simulate_lr(\n","            self, \n","            steps_simulation: int,\n","            steps_per_epoch: int = TRAIN_STEPS) -> list:\n","        self.model = DROPBaseT5.from_pretrained(T5_MODEL)\n","        self.model.compile(optimizer=keras.optimizers.Adam())\n","\n","        # simulate training\n","        for global_step in range(steps_simulation):\n","            batch_n = global_step % steps_per_epoch\n","            if batch_n == 0:\n","                self.on_epoch_begin(global_step // steps_per_epoch)\n","            self.on_batch_begin(batch_n)\n","            self.on_batch_end(batch_n)\n","\n","        # plot epoch lr\n","        x = range(1, len(self.__lr_actual) + 1)\n","        print('')\n","        fig, ax = plt.subplots(figsize=(15, 6))\n","        ax.set_title(f'LR Epoch Schedule', fontsize=14, pad=11)\n","        ax.set_ylabel('Learning Rate')\n","        ax.set_xlabel('Epoch')\n","        ax.plot(x, self.__lr_actual)\n","        plt.show()\n","\n","        return self.__lr_actual\n","\n","def get_continous_training_lr_list(\n","                            warmup_batches: int,\n","                            lr_warmup_start: int = LR_WARMUP_START,\n","                            lr_warmup_end: int = LR_WARMUP_END,\n","                            lr_min: float = LR_MIN,\n","                            decay_rate: float = LR_DECAY_RATE_LINEAR,\n","                            epochs_continue: dict = EPOCHS_CONTINUE,\n","                            training_steps: int = TRAIN_STEPS) -> list:\n","    # first, simulate the entire training schedule as if it is nonstop\n","    total_train_step = epochs_continue['epoch_total'] * TRAIN_STEPS\n","    lrs = LRScheduler(\n","                warmup_batches      = warmup_batches, \n","                lr_warmup_start     = lr_warmup_start, \n","                lr_warmup_end       = lr_warmup_end, \n","                lr_min              = lr_min,\n","                decay_rate          = decay_rate,\n","                verbose             = 0)\n","    lr_epochs_simulated = lrs.simulate_lr(total_train_step, TRAIN_STEPS, False)\n","\n","    # second, extract the learning rates from the simulated epochs \n","    return lr_epochs_simulated[\n","                        epochs_continue['epoch_start']-1:\n","                        epochs_continue['epoch_end']:\n","                        1]"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"executionInfo":{"elapsed":4776,"status":"ok","timestamp":1670471055410,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"},"user_tz":300},"id":"nQ-jDYCOvxiy","outputId":"8f7434c5-f0af-41a1-c83b-233f63a04a4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Nonstop training mode...\n"]},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing DROPBaseT5.\n","\n","All the layers of DROPBaseT5 were initialized from the model checkpoint at t5-small.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DROPBaseT5 for predictions without further training.\n","No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Steps per epoch: 2419\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\n","Ending LR: 0.0001\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# simulate and plot the learning rates for training\n","if LR_DO_WARMUP_DECAY:\n","    if EPOCHS_CONTINUE['doit']:\n","        print('Continous training mode...')\n","        lr_epochs_continue = get_continous_training_lr_list(TRAIN_STEPS * WARMP_UP_EPOCHS)\n","        lrs_simple = LRSimpleScheduler(lr_epochs_continue)\n","        total_train_step = (EPOCHS_CONTINUE['epoch_end'] - EPOCHS_CONTINUE['epoch_start']) * TRAIN_STEPS\n","        lr_simple_epochs_simulated = lrs_simple.simulate_lr(total_train_step, TRAIN_STEPS)\n","    else:\n","        print('Nonstop training mode...')\n","        total_train_step = EPOCHS * TRAIN_STEPS\n","        lrs = LRScheduler(\n","                    warmup_batches      = TRAIN_STEPS * WARMP_UP_EPOCHS, \n","                    lr_warmup_start     = LR_WARMUP_START, \n","                    lr_warmup_end       = LR_WARMUP_END, \n","                    lr_min              = LR_MIN,\n","                    decay_rate          = LR_DECAY_RATE_LINEAR,\n","                    verbose             = 0)\n","        \n","        lrs.simulate_lr(total_train_step, TRAIN_STEPS)\n","else:\n","    print('Warning: No learning rate decay is scheduled...')"]},{"cell_type":"markdown","source":["## Corrections to HDF5 file \n","\n","Removing extra relative_attention_bias weight from .h5 file to incorporate Transformer 4.23 updates."],"metadata":{"id":"isu6Ux-wzWsd"}},{"cell_type":"code","source":["import h5py\n","path = '/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/models/rc_exp_1_stage_3_5_e60_drop/model_train_end.h5'\n","\n","with h5py.File(path, \"a\") as f:\n","    del f['decoder/drop_base_t5/decoder/block_._0/layer_._1/EncDecAttention/relative_attention_bias']\n","    f['decoder'].attrs['weight_names'] = np.delete(f['decoder'].attrs['weight_names'], 10)\n","    try:\n","        del f['decoder/drop_base_t5/decoder/block_._0/layer_._1/EncDecAttention/relative_attention_bias'].value\n","    except KeyError as err:\n","        # print(err)\n","        pass\n","\n","print(os.path.getsize(path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hllhgx34zE98","executionInfo":{"status":"ok","timestamp":1670470480091,"user_tz":300,"elapsed":257,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}},"outputId":"66ffaf9c-14d4-4f82-ca18-ca45eaae52c0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["242303936\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0Afk9YVtDKQ"},"outputs":[],"source":["# NOTE: Training can be performed on top of anotheran existing trained model. This\n","# is required for both \"continuous training\" and \"stage training.\" Refer to the \n","# global config section for more details on \"continuous training\" and \"stage training.\"\n","\n","# model loading configs\n","TRAIN_LOAD_MODEL = True\n","TRAIN_MODEL_PATH = '/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/models/rc_exp_1_stage_3_5_e60_drop/model_train_end.h5'\n","\n","TRAIN_MODEL = 't5-small'\n","\n","\n","# ------------------------------------------------------------------------------\n","# BUILD MODEL\n","\n","keras.backend.clear_session() \n","with strategy.scope(): \n","    if TRAIN_LOAD_MODEL:    \n","            model = DROPBaseT5.from_pretrained(TRAIN_MODEL)\n","            model.compile()  \n","            model.load_weights(TRAIN_MODEL_PATH)\n","    else:\n","        optimizer = keras.optimizers.Adam(learning_rate=LR_CONSTANT)\n","        model = DROPBaseT5.from_pretrained(T5_MODEL)\n","        model.compile(optimizer=optimizer)\n","\n","# ------------------------------------------------------------------------------\n","# BUILD CALLBACKS\n","\n","callbacks = []\n","\n","# LR schedule\n","if LR_DO_WARMUP_DECAY:\n","    if EPOCHS_CONTINUE['doit']:\n","        # first, simulate the entire training schedule as if it is nonstop\n","        lr_epochs_continue = get_continous_training_lr_list(TRAIN_STEPS * WARMP_UP_EPOCHS)\n","        lr_epochs_simulated = lrs.simulate_lr(total_train_step, TRAIN_STEPS, False)\n","\n","        # second, extract the learning rates from the simulated epochs \n","        lr_epochs_continue = lr_epochs_simulated[\n","                                            EPOCHS_CONTINUE['epoch_start']-1:\n","                                            EPOCHS_CONTINUE['epoch_end']:\n","                                            1]\n","\n","        # lastly, build the LR schedule for the current training\n","        lrs = LRSimpleScheduler(lr_epochs_continue)\n","    else:\n","        lrs = LRScheduler(\n","                    warmup_batches   = TRAIN_STEPS * WARMP_UP_EPOCHS, \n","                    lr_warmup_start  = LR_WARMUP_START, \n","                    lr_warmup_end    = LR_WARMUP_END, \n","                    lr_min           = LR_MIN,\n","                    decay_rate       = LR_DECAY_RATE_LINEAR,\n","                    verbose          = 0)\n","    callbacks.append(lrs)\n","\n","# callback to save best model \n","time = datetime.utcnow().strftime(f'%m-%d-%H%M%S')\n","model_save_dir = f'{MODEL_SAVE_PATH}/{T5_MODEL}_{time}'\n","if SAVE_MODEL_CHECKPOINTS_LOCAL:\n","    os.mkdir(model_save_dir)\n","    checkpoint_path = f'{model_save_dir}/model_best_chkpt_' + 'e_{epoch:02d}_vl_{val_loss:.8f}.h5'\n","\n","    if SAVE_MODEL_WEIGHTS_ONLY:\n","        options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n","    else:\n","        options = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n","    callback_checkpoint = keras.callbacks.ModelCheckpoint(\n","                                            filepath=checkpoint_path,\n","                                            save_weights_only=SAVE_MODEL_WEIGHTS_ONLY,\n","                                            monitor='val_loss',\n","                                            mode='min',\n","                                            save_best_only=SAVE_BEST_MODEL_ONLY,\n","                                            options=options,\n","                                            verbose=1)\n","    callbacks.append(callback_checkpoint)\n","\n","# callback to render tensorboard\n","if SHOW_TENSORBOARD:\n","    # TENSORBOARD_LOG_PATH must a GCP storage bucket if the model is running on TPU\n","    callback_tensorboard = keras.callbacks.TensorBoard(\n","                                                log_dir=TENSORBOARD_LOG_PATH, \n","                                                histogram_freq=1)\n","    callbacks.append(callback_tensorboard)\n","\n","# callback for wandb tracker\n","if SHOW_WANDB:\n","    callback_wandb = wandb.keras.WandbCallback(\n","                                        monitor='val_loss',\n","                                        mode='min',\n","                                        save_model=SAVE_MODEL_CHECKPOINTS_WANDB,\n","                                        save_weights_only=SAVE_MODEL_WEIGHTS_ONLY)\n","    callbacks.append(callback_wandb)\n","\n","# ------------------------------------------------------------------------------\n","# TRAINING\n","\n","# NOTE: Do NOT specify batch_size!\n","# DOC: Integer or None. Number of samples per gradient update. If unspecified, \n","# batch_size will default to 32. Do not specify the batch_size if your data is \n","# in the form of datasets, generators, or keras.utils.Sequence instances (since \n","# they generate batches).\n","\n","# TRAIN_STEPS = math.ceil(DROP_TRAIN_EXAMPLE_COUNT / BATCH_SIZE)\n","# VALID_STEPS = math.ceil(DROP_DEV_EXAMPLE_COUNT / BATCH_SIZE)\n","train_steps = math.ceil(int(sum(max_ds_size)) / BATCH_SIZE)#DROP_TRAIN_EXAMPLE_COUNT / BATCH_SIZE)\n","valid_steps = math.ceil(DROP_DEV_EXAMPLE_COUNT / BATCH_SIZE)\n","\n","tf.get_logger().setLevel(\"ERROR\")\n","model.fit(\n","    x=train_ds, \n","    validation_data=val_ds,\n","    epochs=EPOCHS,\n","    callbacks=callbacks,\n","    steps_per_epoch=train_steps,\n","    validation_steps=valid_steps,\n","    verbose=1)\n","\n","if SAVE_TRAINED_MODEL:\n","    # save trained model\n","    model.save_weights(f'{model_save_dir}/model_train_end.h5') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YBB9wqbDzu3","executionInfo":{"status":"aborted","timestamp":1670470344526,"user_tz":300,"elapsed":29363,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}}},"outputs":[],"source":["model_save_name = 'musique_.h5'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","torch.save(model.state_dict(), path)"]},{"cell_type":"markdown","metadata":{"id":"d-8fXxHVF3c8"},"source":["## Performance Evaluation\n","The section includes classes and codes used to evaluate the performance of the model according to the [DROP paper](https://allennlp.org/drop). "]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ELCG2elfHd99","executionInfo":{"status":"ok","timestamp":1670471110396,"user_tz":300,"elapsed":215,"user":{"displayName":"Aditya Todi","userId":"10248346743565219821"}}},"outputs":[],"source":["class DropPerformanceMeasure:\n","    def __init__(self, tokenizer: transformers.PreTrainedTokenizer) -> None:\n","        self.__metric = DropEmAndF1()\n","        self.__parsed_examples = []\n","        self.__tokenizer = tokenizer\n","        self.__preds = {}\n","        self.__time = datetime.utcnow().strftime(f'%m%d%H%M%S')\n","        self.__csv_save_path= ''\n","\n","    def load_parse_drop_json_for_eval(\n","                    self,\n","                    json_url: str = DROP_DEV_JSON, \n","                    example_count: int = DROP_DEV_EXAMPLE_COUNT,\n","                    test_mode: bool = False) -> int:\n","        \"\"\" Parse Drop json and reconstruct the DROP dataset. \n","        Returns:\n","            (int) Total number of examples parsed.\n","        \"\"\"\n","        with open(json_url) as f:\n","            drop_dict = json.load(f)\n","\n","            # examples = []\n","            input_ids                  = []\n","            attention_masks            = []\n","            answer_types               = []\n","            answer_dicts               = []\n","            validated_answers_dicts    = []\n","            query_ids                  = []\n","            print(f'Parsing \"{json_url}\"...')\n","            with tqdm(total=example_count) as pbar:\n","                for key, json_example in drop_dict.items():\n","                    context = json_example['passage']\n","                    for qa_dict in json_example['qa_pairs']:\n","                        question = qa_dict['question']\n","                        answer = qa_dict['answer']\n","                        _, answer_type = self.__parse_answer(qa_dict['answer'])\n","                        query_id = qa_dict['query_id']\n","                        if 'validated_answers' in qa_dict:\n","                            validated_answers = qa_dict['validated_answers']\n","                        else:\n","                            validated_answers = None\n","                        if answer is None:\n","                            print(f'Skip {query_id} due to None answer...')\n","                            continue\n","\n","                        input_text = f\"answer_me: {question} context: {context}\"\n","                        encoded_query = self.__tokenizer(\n","                                                    input_text, \n","                                                    return_tensors='tf', \n","                                                    padding='max_length', \n","                                                    truncation=True, \n","                                                    max_length=ENCODER_MAX_LEN)\n","\n","                        input_ids.append(encoded_query[\"input_ids\"][0])                  \n","                        attention_masks.append(encoded_query[\"attention_mask\"][0])            \n","                        answer_types.append(answer_type)               \n","                        answer_dicts.append(answer)               \n","                        validated_answers_dicts.append(validated_answers)    \n","                        query_ids.append(query_id)                  \n","\n","                        pbar.update(1)\n","\n","                        if test_mode:\n","                            # parse only one passge & its questions\n","                            break\n","        \n","        self.__parsed_examples = {\n","                'input_ids'                 : input_ids,\n","                'attention_mask'            : attention_masks,\n","                'answer_type'               : answer_types,\n","                'answer_dict'               : answer_dicts,\n","                'validated_answers_dict'    : validated_answers_dicts,\n","                'query_id'                  : query_ids\n","        }\n","\n","        return len(input_ids)\n","\n","    def __parse_answer(\n","                    self, \n","                    answer_dict: dict, \n","                    spans_sep_token: str = '<ss>') -> str:\n","        \"\"\"Parse the answer json node to string. Spans answers will be seperated \n","        using spans_sep_token.\n","        \"\"\"\n","        number = answer_dict['number'].strip()\n","        if number:\n","            return number, 'n'\n","        \n","        spans = answer_dict['spans']\n","        spans_str = spans_sep_token.join([span.strip() for span in spans if span.strip()])\n","        if spans_str:\n","            if len(spans) > 1:\n","                return spans_str, 's'\n","            else:\n","                return spans_str, 'ss'\n","        \n","        date = answer_dict['date']\n","        if len(date) != 3:\n","            return None, None\n","        date = ' '.join([d.strip() for d in [date['day'], date['month'], date['year']] if d.strip()])\n","        if date:\n","            return date, 'd'\n","        \n","        return None, None\n","    \n","    def __parse_validated_answers(\n","                        self, \n","                        validated_answers: list, \n","                        sep_token: str = '<sv>') -> str:\n","        \"\"\"Parse validated_answers json node to string using sep_token.\n","        \"\"\"\n","        if validated_answers is None:\n","            return ''\n","\n","        answers = []\n","        for answer_dict in validated_answers:\n","            ans, _ = self.__parse_answer(answer_dict)\n","            answers.append(ans)\n","        return sep_token.join([a.strip() for a in answers if a.strip()])\n","\n","    def __to_tf_dataset(\n","            self,\n","            parsed_examples: dict, \n","            max_len: int = 512,\n","            batch_size: int = BATCH_SIZE,\n","            test_reduce_data: bool = False) -> tf.data.Dataset:\n","        # convert to hugging face ds\n","        ds = datasets.Dataset.from_dict(parsed_examples)\n","        if test_reduce_data:\n","            test_ds = datasets.Dataset.from_dict(test_ds[:10])\n","            test_quids = test_quids[:10]\n","        \n","        # convert to tf ds\n","        columns = [\n","                'input_ids', \n","                'attention_mask']\n","        ds.set_format(type='tensorflow', columns=columns)\n","        ds_tf = {x: ds[x]\n","                        for x in [\n","                            'input_ids', \n","                            'attention_mask']}        \n","        ds_tf = tf.data.Dataset.from_tensor_slices(ds_tf)\n","        ds_tf = ds_tf.repeat(1)\n","        ds_tf = ds_tf.batch(batch_size)\n","        ds_tf = ds_tf.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","        return ds_tf\n","\n","    def predict(\n","            self,\n","            model: transformers.TFT5ForConditionalGeneration, \n","            ds_example_count: int = 0,\n","            decoder_max_len: int = DECODER_MAX_LEN,\n","            batch_size: int = BATCH_SIZE,\n","            dry_run: bool = False) -> dict:\n","        \"\"\"Predict and decode using the trained T5 model.\n","        Refs:\n","            https://tinyurl.com/yxlr4jmb\n","            https://tinyurl.com/y53l7vfm\n","        Returns:\n","            (tuple) (preds, labels, types)\n","        \"\"\"\n","        if len(self.__parsed_examples) == 0:\n","            return None\n","        \n","        def fix_output_spacing(s: str) -> str:\n","            \"\"\"Fixing the odd bug that numerical numbers are losing a whitespace in \n","            front after adding digits to special tokens.\n","            \"\"\"\n","            match = re.compile(r'([a-z]|,|-)(\\d)')\n","            s = re.sub(match, r'\\1 \\2', s)\n","            match = re.compile(r'(\\d|[a-z])( )?(-)( )?(\\d|[a-z])')\n","            s = re.sub(match, r'\\1\\3\\5', s)\n","            return s\n","\n","        ds = self.__to_tf_dataset(self.__parsed_examples, batch_size=batch_size)        \n","        with tqdm(total=ds_example_count) as pbar:\n","            inputs, preds = [], []\n","            for batch in ds:\n","                outs_pred = model.generate(\n","                                input_ids=batch['input_ids'], \n","                                attention_mask=batch['attention_mask'],\n","                                max_length=decoder_max_len)\n","                \n","                # detokenize and fix the output whitespace bug in front of numbers\n","                outs_pred = [fix_output_spacing(self.__tokenizer.decode(ids))\n","                             for ids in outs_pred]\n","                preds.extend(outs_pred)\n","\n","                # inputs\n","                ins = batch['input_ids']\n","                ins = [self.__tokenizer.decode(input) for input in ins]\n","                inputs.extend(ins)\n","\n","                # update progress bar\n","                pbar.update(len(batch['input_ids']))\n","                if dry_run:\n","                    # process only one batch if dry run\n","                    break\n","                    \n","        self.__preds['inputs'] = inputs\n","        self.__preds['predictions'] = preds\n","        self.__preds['answer_dict'] = self.__parsed_examples['answer_dict']\n","        self.__preds['answer_type'] = self.__parsed_examples['answer_type']\n","        self.__preds['query_id'] = self.__parsed_examples['query_id']\n","        self.__preds['validated_answers_dict'] = self.__parsed_examples['validated_answers_dict']\n","\n","        return self.__preds\n","\n","    def evaluate(\n","            self, \n","            query_id: list,\n","            answer_dict: list,\n","            validated_answers_dict: list,\n","            answer_type: list,\n","            predictions: list,\n","            prediction_spans_sep_token: str = '<ss>',\n","            print_reports: bool = True) -> tuple:\n","        \"\"\"Evaluate a batch.\n","        Refs:\n","            https://tinyurl.com/yyuuvc5b\n","            https://tinyurl.com/y6rmrp85\n","        \"\"\"\n","        metric_overall = DropEmAndF1()\n","        errors = []\n","        for qid, ans, ans_validated, ans_type, pred in zip(\n","                                                query_id,\n","                                                answer_dict, \n","                                                validated_answers_dict,\n","                                                answer_type,\n","                                                predictions):\n","            # build predction for evaluation\n","            if ans_type == 's': # spans answer\n","                prediction_parsed = pred.split(prediction_spans_sep_token)\n","            else:\n","                prediction_parsed = pred\n","\n","            # build truths for evaluation\n","            ground_truths = [ans]\n","            if ans_validated is not None:\n","                ground_truths.extend(ans_validated)\n","            \n","            # track performance per example\n","            metric_example = DropEmAndF1()\n","            metric_example(prediction=prediction_parsed, ground_truths=ground_truths)\n","            example_exact_match, exampe_f1_score = metric_example.get_metric()\n","            \n","            ans_parsed, _ = self.__parse_answer(ans)\n","            ans_val = self.__parse_validated_answers(ans_validated)\n","            \n","            # add to error report\n","            if exampe_f1_score < 1:\n","                example_error = {\n","                        'query_id'          : qid,\n","                        'prediction'        : pred,\n","                        'answer'            : ans_parsed,\n","                        'validated_answers' : ans_val,\n","                        'f1'                : exampe_f1_score,\n","                        'exact_match'       : example_exact_match\n","                }\n","                errors.append(example_error)\n","\n","            # update metrics\n","            metric_overall(prediction=prediction_parsed, ground_truths=ground_truths)\n","\n","        exact_match, f1_score = metric_overall.get_metric()\n","        return exact_match, f1_score, errors\n","    \n","    def evaluate_by_type(\n","                    self, \n","                    prediction_spans_sep_token: str = '<ss>',\n","                    print_reports: bool = True,\n","                    error_print_count: int = 100,\n","                    save_dir: str = None) -> tuple:\n","        \"\"\"Evaluate the performance by question type.\n","        \"\"\"\n","        predictions     = np.array(self.__preds['predictions'])\n","        types           = np.array(self.__preds['answer_type'])\n","        qids            = np.array(self.__preds['query_id'])\n","        inputs          = np.array(self.__preds['inputs'])\n","        answer_dict     = np.array(self.__preds['answer_dict'])\n","        vals            = np.array(self.__preds['validated_answers_dict'])\n","        \n","        types   = types.reshape(types.shape[0])\n","        qids    = qids.reshape(qids.shape[0])\n","        inputs  = inputs.reshape(inputs.shape[0])\n","\n","        types_n     = types=='n'\n","        types_d     = types=='d'\n","        types_ss    = types=='ss'\n","        types_s     = types=='s'\n","\n","        types_n     = types_n.reshape(types_n.shape[0])\n","        types_d     = types_d.reshape(types_d.shape[0])\n","        types_ss    = types_ss.reshape(types_ss.shape[0])\n","        types_s     = types_s.reshape(types_s.shape[0])\n","\n","        number_eval = self.evaluate(\n","                        qids[types_n].tolist(),\n","                        answer_dict[types_n].tolist(),\n","                        vals[types_n].tolist(),\n","                        types[types_n].tolist(),\n","                        predictions[types_n].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","\n","        date_eval = self.evaluate(\n","                        qids[types_d].tolist(),\n","                        answer_dict[types_d].tolist(),\n","                        vals[types_d].tolist(),\n","                        types[types_d].tolist(),\n","                        predictions[types_d].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        span_eval = self.evaluate(\n","                        qids[types_ss].tolist(),\n","                        answer_dict[types_ss].tolist(),\n","                        vals[types_ss].tolist(),\n","                        types[types_ss].tolist(),\n","                        predictions[types_ss].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        spans_eval = self.evaluate(\n","                        qids[types_s].tolist(),\n","                        answer_dict[types_s].tolist(),\n","                        vals[types_s].tolist(),\n","                        types[types_s].tolist(),\n","                        predictions[types_s].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        \n","        evals_cat = {\n","            'number'    : {'exact_match': number_eval[0], 'f1': number_eval[1]},\n","            'date'      : {'exact_match': date_eval[0], 'f1': date_eval[1]},\n","            'span'      : {'exact_match': span_eval[0], 'f1': span_eval[1]},\n","            'spans'     : {'exact_match': spans_eval[0], 'f1': spans_eval[1]}\n","        }\n","        errors_cat = {\n","            'number'    : number_eval[2],\n","            'date'      : date_eval[2],\n","            'sapn'      : span_eval[2],\n","            'spans'     : spans_eval[2]\n","        }\n","\n","        # generate reports\n","        print('\\n\\n')\n","        print('CATEGORY PERFORMANCE')\n","        df_cat = pd.DataFrame(evals_cat)\n","        display(df_cat)\n","\n","        print('\\n\\n')\n","        print('ERROR ANALYSIS')\n","        for item in errors_cat.items():\n","            q_type = item[0]\n","            \n","            # print\n","            print(f'Question Type: {q_type.capitalize()}')\n","            df = pd.DataFrame(item[1])\n","            if df.shape[0] > error_print_count:\n","                df_sample = df.sample(n=error_print_count)\n","            else:\n","                df_sample = df\n","            display(df_sample)\n","            print('\\n')\n","\n","            # save\n","            if save_dir is not None:\n","                path = f'{self.__csv_save_path}/{save_dir}/performace_reports_{self.__time}'\n","            else:\n","                path = f'{self.__csv_save_path}/performace_reports_{self.__time}'\n","            os.makedirs(path, exist_ok=True)\n","            df_cat.to_csv(f'{path}/performance_category.csv')\n","            df_sample.to_csv(f'{path}/ea_{q_type}_sample_{df_sample.shape[0]}.csv')\n","            df.to_csv(f'{path}/ea_{q_type}_full_{df.shape[0]}.csv')\n","        \n","        print(f\"\\nError reports have been saved to {path}!\")\n","\n","        return evals_cat, errors_cat\n","\n","    def __get_errors(\n","                self,\n","                predictions: np.ndarray,\n","                truths: np.ndarray,\n","                qids: np.ndarray,\n","                inputs: np.ndarray) -> dict:\n","        filter_ = predictions != truths\n","        return {\n","            'query_ids': qids[filter_],\n","            'predictions': predictions[filter_], \n","            'truths': truths[filter_],\n","            'inputs': inputs[filter_]}\n","\n","    def evaluate_all(\n","                self, \n","                save_dir: str = None,\n","                prediction_spans_sep_token: str = '<ss>') -> None:\n","        exact_match, f1_score, _ = self.evaluate(\n","                                        self.__preds['query_id'], \n","                                        self.__preds['answer_dict'], \n","                                        self.__preds['validated_answers_dict'],\n","                                        self.__preds['answer_type'],\n","                                        self.__preds['predictions'],\n","                                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        \"\"\"Evaluate the performance across the entire dataset.\n","        \"\"\"\n","        # generate eval report\n","        print('')\n","        print('OVERALL PERFORMANCE')\n","        evals_overall = {'exact_match': exact_match, 'f1': f1_score}\n","        df_overall = pd.DataFrame(evals_overall, index=[0])\n","        display(df_overall.style.hide_index())\n","\n","        # save report\n","        if save_dir is not None:\n","            path = f'{self.__csv_save_path}/{save_dir}/performace_reports_{self.__time}'\n","            \n","        else:\n","            path = f'{self.__csv_save_path}/performace_reports_{self.__time}'\n","        os.makedirs(path, exist_ok=True)\n","        df_overall.to_csv(f'{path}/performance_overall.csv')\n","\n","    def get_eval_reports(\n","                    self, \n","                    csv_save_path: str,\n","                    prediction_spans_sep_token: str = '<ss>',\n","                    print_reports: bool = True,\n","                    grouping_dir: str = None) -> None:\n","        \"\"\"Function to produce the performance evaluation report.\n","        Args:\n","            csv_save_path: Path to the folder where the reports will be saved to.\n","            prediction_spans_sep_token: Token used to separate the different answers for spans.\n","            print_reports: Set true to print sample reports in the notebook.\n","            grouping_dir: Optional; folder to be created under csv_save_path for saving the reports.\n","        \"\"\"\n","        self.__csv_save_path = csv_save_path\n","        self.evaluate_all(\n","                    save_dir=grouping_dir, \n","                    prediction_spans_sep_token=prediction_spans_sep_token)\n","        self.evaluate_by_type(\n","                    save_dir=grouping_dir,\n","                    prediction_spans_sep_token=prediction_spans_sep_token)\n","    \n","    def reset(self) -> None:\n","        self.__metric = DropEmAndF1()\n","        self.__parsed_examples = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a96Mnybas_WF"},"outputs":[],"source":["if EVALUATE_DEV:\n","    PRED_LOAD_MODEL = True\n","    PRED_MODEL = 't5-small'\n","    PRED_MODEL_PATH = f'{GDRIVE_REPO_PATH}/musique_evaluation/musique_model_train_end.h5'\n","    EVAL_REPORT_SAVE_PATH = f'{GDRIVE_REPO_PATH}/musique_evaluation/error_reports/'\n","\n","    if PRED_LOAD_MODEL:\n","        keras.backend.clear_session() \n","        with strategy.scope(): \n","            model_pred = DROPBaseT5.from_pretrained(TRAIN_MODEL)\n","            model_pred.compile()\n","            model_pred.load_weights(TRAIN_MODEL_PATH)\n","    else:\n","        model_pred = model\n","\n","    dev_eval = DropPerformanceMeasure(TOKENIZER)\n","    count = dev_eval.load_parse_drop_json_for_eval(test_mode=False)\n","    print(f'Total number of examples to be evaluated: {count}')\n","    dev_eval.predict(\n","                model=model_pred, \n","                # batch_size=10, # only required if dry_run = True\n","                ds_example_count=DROP_DEV_EXAMPLE_COUNT,\n","                dry_run=False)\n","    dev_eval.get_eval_reports(\n","                csv_save_path=EVAL_REPORT_SAVE_PATH,\n","                prediction_spans_sep_token='<ss>')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3896a19c564440e798220672af42c188":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d22f93005e74465a98f3c11c20fac04d","IPY_MODEL_8f701f189ff44010b3a9c5134b485f70","IPY_MODEL_a34330e52b2345d0875abf3468ca2171"],"layout":"IPY_MODEL_4b4a7bfcefff44f3913f8a27917fec01"}},"d22f93005e74465a98f3c11c20fac04d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda89e0f38ed4bf49e67603b4aabcfba","placeholder":"","style":"IPY_MODEL_53c69b5ed851406aa93093a8f2e56d58","value":"Downloading: 100%"}},"8f701f189ff44010b3a9c5134b485f70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_054abbc918034123933a9ceb12e2fe43","max":1197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b285406a23384e4388e327ccb9e18325","value":1197}},"a34330e52b2345d0875abf3468ca2171":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46fc99eb6f6a4a14973c3167dc212c2f","placeholder":"","style":"IPY_MODEL_3c1280c6e6e64acc9b61eadfe18ae2d6","value":" 1.17k/1.17k [00:00&lt;00:00, 39.9kB/s]"}},"4b4a7bfcefff44f3913f8a27917fec01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eda89e0f38ed4bf49e67603b4aabcfba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53c69b5ed851406aa93093a8f2e56d58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"054abbc918034123933a9ceb12e2fe43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b285406a23384e4388e327ccb9e18325":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46fc99eb6f6a4a14973c3167dc212c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1280c6e6e64acc9b61eadfe18ae2d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4a148ffa5c94f22969f7292c26dbc61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e6c0163b6b54389b58174d33ddada0f","IPY_MODEL_81c31392c7cd4e98969c86773d21cf28","IPY_MODEL_b339df998e2c4428bf6ebd0b0255bf4f"],"layout":"IPY_MODEL_3bcb771590b14513acae1d3096dfef37"}},"8e6c0163b6b54389b58174d33ddada0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e6cc33e89784d83b131652ede153113","placeholder":"","style":"IPY_MODEL_ddfdbf0f6a59459eaa1aaee944282e32","value":"Downloading: 100%"}},"81c31392c7cd4e98969c86773d21cf28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d10d6ac40ce44972b5369e2d37c53425","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_183f88b354b541418fb11ee9c6f6c7ea","value":791656}},"b339df998e2c4428bf6ebd0b0255bf4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90af3e4ddc664836a2b37e7e51fde94b","placeholder":"","style":"IPY_MODEL_fada5a52ea8948e08516257349239171","value":" 773k/773k [00:00&lt;00:00, 647kB/s]"}},"3bcb771590b14513acae1d3096dfef37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6cc33e89784d83b131652ede153113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddfdbf0f6a59459eaa1aaee944282e32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d10d6ac40ce44972b5369e2d37c53425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"183f88b354b541418fb11ee9c6f6c7ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90af3e4ddc664836a2b37e7e51fde94b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fada5a52ea8948e08516257349239171":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a28160e8c9184cf6a3b55a9b27e94bd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fc6f032d8384509824cf14908ca7c4c","IPY_MODEL_fd69064f923f4c0280e746908932c3e5","IPY_MODEL_af38ecbc455e4a11b1b88dcf9e03e955"],"layout":"IPY_MODEL_414e9ee2c704475ab93e19284c18fa91"}},"5fc6f032d8384509824cf14908ca7c4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57068558918941f8b7b3d45168fe3fa3","placeholder":"","style":"IPY_MODEL_c36cbb7d4f23407c9fc05977897327da","value":"Downloading: 100%"}},"fd69064f923f4c0280e746908932c3e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_878cf441b2654d3eb472fc74466e1adf","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60d75b20a63849379aad2923a813684c","value":1389353}},"af38ecbc455e4a11b1b88dcf9e03e955":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e590a40cd0d340bb8fba739cdffb7dbb","placeholder":"","style":"IPY_MODEL_9b73f5b62bf44caf808f87b4dce65f99","value":" 1.32M/1.32M [00:00&lt;00:00, 1.69MB/s]"}},"414e9ee2c704475ab93e19284c18fa91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57068558918941f8b7b3d45168fe3fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36cbb7d4f23407c9fc05977897327da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"878cf441b2654d3eb472fc74466e1adf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60d75b20a63849379aad2923a813684c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e590a40cd0d340bb8fba739cdffb7dbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b73f5b62bf44caf808f87b4dce65f99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}