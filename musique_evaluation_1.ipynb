{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a18c218a59854ecda85ffb1a5584e89d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85409ac5f54e455fb49b93d2afec3715","IPY_MODEL_0e7158519aa44bcd898635d4a21d8575","IPY_MODEL_de1515522cd24f5ea74479da1dbb81ba"],"layout":"IPY_MODEL_55317103e2624731b795132ea782f43e"}},"85409ac5f54e455fb49b93d2afec3715":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8e7745fd2b244c2a50022a10caf6e53","placeholder":"​","style":"IPY_MODEL_6252d0f979aa4be7a916fa5186e9d0a1","value":"Downloading: 100%"}},"0e7158519aa44bcd898635d4a21d8575":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9f6c18783254c80b3e34bcd3bea250c","max":1197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fece64aaa7b14879bf0d4b6c4d147280","value":1197}},"de1515522cd24f5ea74479da1dbb81ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e303ff02b5794fecb4cc54381173517a","placeholder":"​","style":"IPY_MODEL_646f023ce1b24eb4a3129248b7fadd67","value":" 1.17k/1.17k [00:00&lt;00:00, 40.9kB/s]"}},"55317103e2624731b795132ea782f43e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8e7745fd2b244c2a50022a10caf6e53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6252d0f979aa4be7a916fa5186e9d0a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f6c18783254c80b3e34bcd3bea250c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fece64aaa7b14879bf0d4b6c4d147280":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e303ff02b5794fecb4cc54381173517a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"646f023ce1b24eb4a3129248b7fadd67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acd2846d34da4557b1de2f54068ab580":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e55c3e2c7b34d8d96968f16a7b35f5c","IPY_MODEL_6ab210b8ea5c4a1b8215ff3ff5d7dcfd","IPY_MODEL_56cbda9f17114224a5ae04d0c785a27d"],"layout":"IPY_MODEL_84aa1d35e5ec45519a003938c1c4710d"}},"0e55c3e2c7b34d8d96968f16a7b35f5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7dbd6bcd50a4e68abb0ec351ce51eb0","placeholder":"​","style":"IPY_MODEL_b1290391d22141909586326bf121618b","value":"Downloading: 100%"}},"6ab210b8ea5c4a1b8215ff3ff5d7dcfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4ac285af773447fa1a613da3099250f","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bb1e9b09b95452b9efcb5bc9b2ad53a","value":791656}},"56cbda9f17114224a5ae04d0c785a27d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_435db3f76a7344eba1463d4abec2b590","placeholder":"​","style":"IPY_MODEL_b35598cbe182416c8267c551206656f3","value":" 773k/773k [00:00&lt;00:00, 2.59MB/s]"}},"84aa1d35e5ec45519a003938c1c4710d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7dbd6bcd50a4e68abb0ec351ce51eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1290391d22141909586326bf121618b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4ac285af773447fa1a613da3099250f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bb1e9b09b95452b9efcb5bc9b2ad53a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"435db3f76a7344eba1463d4abec2b590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b35598cbe182416c8267c551206656f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0343e71dd24a4adf92d0a5faa85aad3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04678d348f8e4de68e566061ea42c616","IPY_MODEL_d291b16651064d86b9a5531cfabd8c9c","IPY_MODEL_a602011ec4e84ee496a7ecb41136153c"],"layout":"IPY_MODEL_4334edf740884cdd83c095ef903c659f"}},"04678d348f8e4de68e566061ea42c616":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83e70fce3c7741c38d8402c3c4e69c4b","placeholder":"​","style":"IPY_MODEL_840b8708ee7344db93b3aaa800e3ccb4","value":"Downloading: 100%"}},"d291b16651064d86b9a5531cfabd8c9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80967c65644145efbf4a8cb341e658dd","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba3c566d437f4bdf84baf0911f7e31c0","value":1389353}},"a602011ec4e84ee496a7ecb41136153c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_421ed0a2a9884eaf87170cd2db96620f","placeholder":"​","style":"IPY_MODEL_4f76b379999c417a8deb933e20ae60f4","value":" 1.32M/1.32M [00:00&lt;00:00, 1.76MB/s]"}},"4334edf740884cdd83c095ef903c659f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e70fce3c7741c38d8402c3c4e69c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840b8708ee7344db93b3aaa800e3ccb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80967c65644145efbf4a8cb341e658dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba3c566d437f4bdf84baf0911f7e31c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"421ed0a2a9884eaf87170cd2db96620f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f76b379999c417a8deb933e20ae60f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"018b1eb30edd44f799a2152dc6c79682":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8949e0383b9f45c68b2e1038da27a5cd","IPY_MODEL_f222eb5621cf41518d610bd219c923b9","IPY_MODEL_a15b6bd14b32473ab354c1825aa542cf"],"layout":"IPY_MODEL_f1b8ae1710d84b628898a68e8eec45a6"}},"8949e0383b9f45c68b2e1038da27a5cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f47f3f26ab442e89f766e0c7a89d0f1","placeholder":"​","style":"IPY_MODEL_c5a84c8e41e54835bcc5b4882e9128ed","value":" 50%"}},"f222eb5621cf41518d610bd219c923b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ddfb944cf24470d847179a52d3cdaf2","max":4834,"min":0,"orientation":"horizontal","style":"IPY_MODEL_287d98550f854247ba9712ed037a73e6","value":2417}},"a15b6bd14b32473ab354c1825aa542cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ecaa14db5d347f7a89a6e7c99c0ae77","placeholder":"​","style":"IPY_MODEL_6c8e09601bd24ce38777b1aea050a8fe","value":" 2417/4834 [00:17&lt;00:19, 122.61it/s]"}},"f1b8ae1710d84b628898a68e8eec45a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f47f3f26ab442e89f766e0c7a89d0f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a84c8e41e54835bcc5b4882e9128ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ddfb944cf24470d847179a52d3cdaf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"287d98550f854247ba9712ed037a73e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ecaa14db5d347f7a89a6e7c99c0ae77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8e09601bd24ce38777b1aea050a8fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0914e701652142da8947fb5ced8fb783":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95df437f414b4a51922e52b2461f0b35","IPY_MODEL_3cecaec9073d46caaa8b387cc082bdd4","IPY_MODEL_a03332f4f7174c97bbdd193727b2643d"],"layout":"IPY_MODEL_24410b4e497c4a54b183febca30a4810"}},"95df437f414b4a51922e52b2461f0b35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be1eadf06a6440cd82e4226e9522366c","placeholder":"​","style":"IPY_MODEL_ded41c42657c4959aed8fb3cea9c5618","value":" 50%"}},"3cecaec9073d46caaa8b387cc082bdd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2f17e34f0e41f886564a608f173855","max":4834,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8216176500cb46288e6d6f8bf94d10ef","value":2417}},"a03332f4f7174c97bbdd193727b2643d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b961ae05ffff4dfb8310e77cef42a2dc","placeholder":"​","style":"IPY_MODEL_0f4653bca1914e77b533b8a85ff8061c","value":" 2417/4834 [09:21&lt;11:16,  3.57it/s]"}},"24410b4e497c4a54b183febca30a4810":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be1eadf06a6440cd82e4226e9522366c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ded41c42657c4959aed8fb3cea9c5618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a2f17e34f0e41f886564a608f173855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8216176500cb46288e6d6f8bf94d10ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b961ae05ffff4dfb8310e77cef42a2dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4653bca1914e77b533b8a85ff8061c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BOp61GCQPMP","executionInfo":{"status":"ok","timestamp":1670227482464,"user_tz":300,"elapsed":616,"user":{"displayName":"Samruddhi Patil","userId":"13079939565654431898"}},"outputId":"258c4ed4-61eb-4319-8658-772ffb2c4072"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["update-alternatives: error: alternative path /usr/bin/python3.7 doesn't exist\n"]}]},{"cell_type":"code","source":["!sudo apt-get install python3.7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPXh3sDwbmFv","executionInfo":{"status":"ok","timestamp":1670229478128,"user_tz":300,"elapsed":14245,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"cad4f068-af02-4c05-abaf-597a99425ab2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n","Suggested packages:\n","  python3.7-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.7-minimal libpython3.7-stdlib python3.7 python3.7-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 7 not upgraded.\n","Need to get 4,446 kB of archives.\n","After this operation, 22.5 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.15-1+bionic1 [589 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.15-1+bionic1 [1,724 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.15-1+bionic1 [1,773 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.15-1+bionic1 [360 kB]\n","Fetched 4,446 kB in 8s (550 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.7-minimal:amd64.\n","(Reading database ... 124015 files and directories currently installed.)\n","Preparing to unpack .../libpython3.7-minimal_3.7.15-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-minimal:amd64 (3.7.15-1+bionic1) ...\n","Selecting previously unselected package python3.7-minimal.\n","Preparing to unpack .../python3.7-minimal_3.7.15-1+bionic1_amd64.deb ...\n","Unpacking python3.7-minimal (3.7.15-1+bionic1) ...\n","Selecting previously unselected package libpython3.7-stdlib:amd64.\n","Preparing to unpack .../libpython3.7-stdlib_3.7.15-1+bionic1_amd64.deb ...\n","Unpacking libpython3.7-stdlib:amd64 (3.7.15-1+bionic1) ...\n","Selecting previously unselected package python3.7.\n","Preparing to unpack .../python3.7_3.7.15-1+bionic1_amd64.deb ...\n","Unpacking python3.7 (3.7.15-1+bionic1) ...\n","Setting up libpython3.7-minimal:amd64 (3.7.15-1+bionic1) ...\n","Setting up python3.7-minimal (3.7.15-1+bionic1) ...\n","Setting up libpython3.7-stdlib:amd64 (3.7.15-1+bionic1) ...\n","Setting up python3.7 (3.7.15-1+bionic1) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"]}]},{"cell_type":"code","source":["!ls -lrt /usr/bin | grep python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjV6UMzUcMAw","executionInfo":{"status":"ok","timestamp":1670236855489,"user_tz":300,"elapsed":330,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"b25de628-5e28-4152-9048-e62f3b8bf2fd"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["lrwxrwxrwx 1 root root         26 Mar 26  2018 pybuild -> ../share/dh-python/pybuild\n","lrwxrwxrwx 1 root root         29 Mar 26  2018 dh_python3 -> ../share/dh-python/dh_python3\n","lrwxrwxrwx 1 root root         26 Mar 26  2018 dh_pypy -> ../share/dh-python/dh_pypy\n","lrwxrwxrwx 1 root root         33 Apr 16  2018 x86_64-linux-gnu-python-config -> x86_64-linux-gnu-python2.7-config\n","lrwxrwxrwx 1 root root         29 Apr 16  2018 pyversions -> ../share/python/pyversions.py\n","lrwxrwxrwx 1 root root         16 Apr 16  2018 python-config -> python2.7-config\n","lrwxrwxrwx 1 root root         16 Apr 16  2018 python2-config -> python2.7-config\n","lrwxrwxrwx 1 root root          9 Apr 16  2018 python2 -> python2.7\n","lrwxrwxrwx 1 root root          9 Apr 16  2018 python -> python2.7\n","-rwxr-xr-x 1 root root       1056 Apr 16  2018 dh_python2\n","lrwxrwxrwx 1 root root         34 Oct 25  2018 x86_64-linux-gnu-python3m-config -> x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root         33 Oct 25  2018 x86_64-linux-gnu-python3-config -> x86_64-linux-gnu-python3.6-config\n","lrwxrwxrwx 1 root root         17 Oct 25  2018 python3m-config -> python3.6m-config\n","lrwxrwxrwx 1 root root         10 Oct 25  2018 python3m -> python3.6m\n","lrwxrwxrwx 1 root root         16 Oct 25  2018 python3-config -> python3.6-config\n","lrwxrwxrwx 1 root root         31 Oct 25  2018 py3versions -> ../share/python3/py3versions.py\n","-rwxr-xr-x 1 root root       3283 Jun 29 11:45 x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root         34 Jun 29 11:45 x86_64-linux-gnu-python3.6-config -> x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root         34 Jun 29 11:45 python3.6m-config -> x86_64-linux-gnu-python3.6m-config\n","-rwxr-xr-x 2 root root    4530520 Jun 29 11:45 python3.6m\n","lrwxrwxrwx 1 root root         33 Jun 29 11:45 python3.6-config -> x86_64-linux-gnu-python3.6-config\n","-rwxr-xr-x 2 root root    4530520 Jun 29 11:45 python3.6\n","lrwxrwxrwx 1 root root         23 Jun 29 11:45 pdb3.6 -> ../lib/python3.6/pdb.py\n","-rwxr-xr-x 1 root root       2971 Jul  1 15:56 x86_64-linux-gnu-python2.7-config\n","lrwxrwxrwx 1 root root         33 Jul  1 15:56 python2.7-config -> x86_64-linux-gnu-python2.7-config\n","-rwxr-xr-x 1 root root    3624880 Jul  1 15:56 python2.7\n","lrwxrwxrwx 1 root root         23 Jul  1 15:56 pdb2.7 -> ../lib/python2.7/pdb.py\n","-rwxr-xr-x 1 root root       3151 Oct 12 19:14 x86_64-linux-gnu-python3.8-config\n","lrwxrwxrwx 1 root root         33 Oct 12 19:14 python3.8-config -> x86_64-linux-gnu-python3.8-config\n","-rwxr-xr-x 1 root root    5120912 Oct 12 19:14 python3.8\n","lrwxrwxrwx 1 root root         23 Oct 12 19:14 pdb3.8 -> ../lib/python3.8/pdb.py\n","-rwxr-xr-x 2 root root    4836712 Oct 12 19:14 python3.7m\n","-rwxr-xr-x 2 root root    4836712 Oct 12 19:14 python3.7\n","lrwxrwxrwx 1 root root         23 Oct 12 19:14 pdb3.7 -> ../lib/python3.7/pdb.py\n","lrwxrwxrwx 1 root root         25 Dec  1 19:57 python3 -> /etc/alternatives/python3\n"]}]},{"cell_type":"code","source":["!echo $PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJbjg6K4chln","executionInfo":{"status":"ok","timestamp":1670229822314,"user_tz":300,"elapsed":329,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"feeeffa2-354a-4604-a005-22ba073e394d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"]}]},{"cell_type":"code","source":["!ls -lrht /usr/local/bin | grep python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNHCD96hdL0b","executionInfo":{"status":"ok","timestamp":1670229947023,"user_tz":300,"elapsed":827,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"3eeb1de6-5aab-4b6a-89a2-1315d5f37c7f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["-r-xr-xr-x 1 root root 1.4K Jan  1  2000 python\n","-rwxr-xr-x 1 root root  224 Dec  1 20:16 ipython3\n","-rwxr-xr-x 1 root root  224 Dec  1 20:16 ipython\n"]}]},{"cell_type":"code","source":["!ls -lrht /usr/bin | grep python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4hrMDO2Id3d-","executionInfo":{"status":"ok","timestamp":1670230228018,"user_tz":300,"elapsed":414,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"ddac1801-fd99-447a-f166-e1626a2a23c9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["lrwxrwxrwx 1 root root      29 Mar 26  2018 dh_python3 -> ../share/dh-python/dh_python3\n","lrwxrwxrwx 1 root root      34 Oct 25  2018 x86_64-linux-gnu-python3m-config -> x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root      33 Oct 25  2018 x86_64-linux-gnu-python3-config -> x86_64-linux-gnu-python3.6-config\n","lrwxrwxrwx 1 root root      17 Oct 25  2018 python3m-config -> python3.6m-config\n","lrwxrwxrwx 1 root root      10 Oct 25  2018 python3m -> python3.6m\n","lrwxrwxrwx 1 root root      16 Oct 25  2018 python3-config -> python3.6-config\n","lrwxrwxrwx 1 root root      31 Oct 25  2018 py3versions -> ../share/python3/py3versions.py\n","-rwxr-xr-x 1 root root    3.3K Jun 29 11:45 x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root      34 Jun 29 11:45 x86_64-linux-gnu-python3.6-config -> x86_64-linux-gnu-python3.6m-config\n","lrwxrwxrwx 1 root root      34 Jun 29 11:45 python3.6m-config -> x86_64-linux-gnu-python3.6m-config\n","-rwxr-xr-x 2 root root    4.4M Jun 29 11:45 python3.6m\n","lrwxrwxrwx 1 root root      33 Jun 29 11:45 python3.6-config -> x86_64-linux-gnu-python3.6-config\n","-rwxr-xr-x 2 root root    4.4M Jun 29 11:45 python3.6\n","lrwxrwxrwx 1 root root      23 Jun 29 11:45 pdb3.6 -> ../lib/python3.6/pdb.py\n","-rwxr-xr-x 1 root root    3.1K Oct 12 19:14 x86_64-linux-gnu-python3.8-config\n","lrwxrwxrwx 1 root root      33 Oct 12 19:14 python3.8-config -> x86_64-linux-gnu-python3.8-config\n","-rwxr-xr-x 1 root root    4.9M Oct 12 19:14 python3.8\n","lrwxrwxrwx 1 root root      23 Oct 12 19:14 pdb3.8 -> ../lib/python3.8/pdb.py\n","-rwxr-xr-x 2 root root    4.7M Oct 12 19:14 python3.7m\n","-rwxr-xr-x 2 root root    4.7M Oct 12 19:14 python3.7\n","lrwxrwxrwx 1 root root      23 Oct 12 19:14 pdb3.7 -> ../lib/python3.7/pdb.py\n","lrwxrwxrwx 1 root root      25 Dec  1 19:57 python3 -> /etc/alternatives/python3\n"]}]},{"cell_type":"code","source":["!ls -lhrt /etc/alternatives/python3\n","# !rm /etc/alternatives/python3\n","# !ln -s /usr/bin/python3.7 /etc/alternatives/python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1YnmKAzeG11","executionInfo":{"status":"ok","timestamp":1670230203445,"user_tz":300,"elapsed":521,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"71da40c3-a628-410a-9101-851f86610d80"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["lrwxrwxrwx 1 root root 18 Dec  5 08:49 /etc/alternatives/python3 -> /usr/bin/python3.7\n"]}]},{"cell_type":"code","source":["# !ls /usr/bin/ | grep python\n","# !apt-get install python3.7\n","!sudo update-alternatives --config python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huzw06mKRDzQ","outputId":"cbe06beb-4453-4ed9-eb63-7b8fcedabc21","executionInfo":{"status":"ok","timestamp":1670230488931,"user_tz":300,"elapsed":105944,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["update-alternatives: warning: /etc/alternatives/python3 has been changed (manually or by a script); switching to manual updates only\n","There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n","\n","  Selection    Path                Priority   Status\n","------------------------------------------------------------\n","  0            /usr/bin/python3.8   2         auto mode\n","  1            /usr/bin/python3.6   1         manual mode\n","  2            /usr/bin/python3.8   2         manual mode\n","\n","Press <enter> to keep the current choice[*], or type selection number: ^C\n"]}]},{"cell_type":"code","source":["!python -V"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cujtMNnzRMOv","executionInfo":{"status":"ok","timestamp":1670230378027,"user_tz":300,"elapsed":816,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"efa959d5-5b59-4cbf-cf21-192f54f463cf"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.15\n"]}]},{"cell_type":"code","source":["# !python3 -m pip list\n","!python3 -m pip install -U pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkVQuD0mfbvM","executionInfo":{"status":"ok","timestamp":1670233093758,"user_tz":300,"elapsed":4438,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"9cfa81da-2916-4b81-c60f-63c3b4768e8f"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pip\n","  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n","\u001b[K    100% |████████████████████████████████| 2.1MB 729kB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 9.0.1\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","Successfully installed pip-22.3.1\n"]}]},{"cell_type":"code","execution_count":93,"metadata":{"id":"9iFaRFg3ceVO","executionInfo":{"status":"ok","timestamp":1670237499051,"user_tz":300,"elapsed":127178,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"659105e6-fa75-4d8c-a585-3643f778fd8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.11.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n","Requirement already satisfied: tensorflow<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.11.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (22.11.23)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (4.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (65.6.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.16.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.28.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (14.0.6)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.11.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.11.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.51.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (21.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.21.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.1.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.11.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.19.6)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.14.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.7.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.30.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.15.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.28.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.2.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.4.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.0.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (5.2.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.13.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.6)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2022.9.24)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.2.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==3.3 in /usr/local/lib/python3.7/dist-packages (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (3.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (1.21.6)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (0.0.53)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (2022.10.31)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (0.1.97)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (4.64.1)\n","Collecting tokenizers==0.8.1.rc2\n","  Using cached tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.3) (2.28.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==3.3) (2.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3) (2022.9.24)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.3) (2.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3) (1.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3) (8.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3) (1.16.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click->sacremoses->transformers==3.3) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->sacremoses->transformers==3.3) (3.11.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click->sacremoses->transformers==3.3) (4.4.0)\n","Installing collected packages: tokenizers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","Successfully installed tokenizers-0.8.1rc2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.7.1)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.28.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.4.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.26.13)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.11.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gsutil in /usr/local/lib/python3.7/dist-packages (5.17)\n","Requirement already satisfied: pyOpenSSL>=0.13 in /usr/local/lib/python3.7/dist-packages (from gsutil) (22.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from gsutil) (1.16.0)\n","Requirement already satisfied: google-reauth>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from gsutil) (0.1.1)\n","Requirement already satisfied: google-auth[aiohttp]>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from gsutil) (2.15.0)\n","Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from gsutil) (0.18)\n","Requirement already satisfied: retry-decorator>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from gsutil) (1.1.1)\n","Requirement already satisfied: argcomplete>=1.9.4 in /usr/local/lib/python3.7/dist-packages (from gsutil) (2.0.0)\n","Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /usr/local/lib/python3.7/dist-packages (from gsutil) (3.0)\n","Requirement already satisfied: monotonic>=1.4 in /usr/local/lib/python3.7/dist-packages (from gsutil) (1.6)\n","Requirement already satisfied: httplib2==0.20.4 in /usr/local/lib/python3.7/dist-packages (from gsutil) (0.20.4)\n","Requirement already satisfied: google-apitools>=0.5.32 in /usr/local/lib/python3.7/dist-packages (from gsutil) (0.5.32)\n","Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.7/dist-packages (from gsutil) (1.7)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from httplib2==0.20.4->gsutil) (3.0.9)\n","Requirement already satisfied: importlib-metadata<5,>=0.23 in /usr/local/lib/python3.7/dist-packages (from argcomplete>=1.9.4->gsutil) (4.13.0)\n","Requirement already satisfied: rsa==4.7.2 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (4.7.2)\n","Requirement already satisfied: boto>=2.29.1 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (2.49.0)\n","Requirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (4.1.3)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil) (0.4.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (0.2.8)\n","Requirement already satisfied: requests<3.0.0dev,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (2.28.1)\n","Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (3.8.3)\n","Requirement already satisfied: pyu2f in /usr/local/lib/python3.7/dist-packages (from google-reauth>=0.1.0->gsutil) (0.1.5)\n","Requirement already satisfied: cryptography<39,>=38.0.0 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.13->gsutil) (38.0.4)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (6.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (4.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (22.1.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (2.1.1)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography<39,>=38.0.0->pyOpenSSL>=0.13->gsutil) (1.15.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5,>=0.23->argcomplete>=1.9.4->gsutil) (3.11.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2022.9.24)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (1.26.13)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography<39,>=38.0.0->pyOpenSSL>=0.13->gsutil) (2.21)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.5)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.9.4)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.29)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.11)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.11.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.28.1)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.16.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.19.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (65.6.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.1.3)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from Click!=8.0.0,>=7.0->wandb) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.4.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.6)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->Click!=8.0.0,>=7.0->wandb) (3.11.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting allennlp-models\n","  Using cached allennlp_models-2.10.1-py3-none-any.whl (464 kB)\n","Collecting allennlp<2.11,>=2.10.1\n","  Using cached allennlp-2.10.1-py3-none-any.whl (730 kB)\n","Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp-models) (1.1)\n","Collecting ftfy\n","  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n","Collecting nltk>=3.6.5\n","  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n","Collecting torch<1.13.0,>=1.7.0\n","tcmalloc: large alloc 1073750016 bytes == 0xa0158000 @  0x7fc96d05b2a4 0x58ead6 0x441ff3 0x5d1f81 0x5d2306 0x58f62c 0x5105e2 0x5b4ee6 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x4bad0a 0x4d3249 0x591e56 0x50e18c 0x5b4ee6 0x4bad0a 0x4d3249 0x591e56 0x50e18c 0x5b4ee6 0x4bad0a 0x4d3249 0x591e56 0x50e18c 0x5b575e\n","  Using cached torch-1.12.1-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from allennlp-models) (2.7.1)\n","Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp-models) (1.1)\n","Collecting conllu==4.4.2\n","  Using cached conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n","Collecting fairscale==0.4.6\n","  Using cached fairscale-0.4.6-py3-none-any.whl\n","Collecting torchvision<0.14.0,>=0.8.1\n","  Using cached torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n","Collecting scipy>=1.7.3\n","  Using cached scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","Collecting tensorboardX>=1.2\n","  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","Collecting filelock<3.8,>=3.3\n","  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (3.7.0)\n","Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (3.19.6)\n","Collecting jsonnet>=0.10.0\n","  Using cached jsonnet-0.19.1.tar.gz (593 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (2.28.1)\n","Requirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (1.21.6)\n","Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (1.1.0)\n","Collecting pytest>=6.2.5\n","  Using cached pytest-7.2.0-py3-none-any.whl (316 kB)\n","Collecting typer>=0.4.1\n","  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n","Collecting spacy<3.4,>=2.1.0\n","  Using cached spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","Collecting transformers<4.21,>=4.1\n","  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","Collecting scikit-learn>=1.0.1\n","  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n","Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (4.64.1)\n","Collecting more-itertools>=8.12.0\n","  Using cached more_itertools-9.0.0-py3-none-any.whl (52 kB)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (0.0.53)\n","Collecting traitlets>5.1.1\n","  Using cached traitlets-5.6.0-py3-none-any.whl (107 kB)\n","Requirement already satisfied: lmdb>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (1.3.0)\n","Requirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (0.11.1)\n","Collecting cached-path<1.2.0,>=1.1.3\n","  Using cached cached_path-1.1.6-py3-none-any.whl (26 kB)\n","Requirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (0.1.97)\n","Collecting base58>=2.1.1\n","  Using cached base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Collecting wandb<0.13.0,>=0.10.0\n","  Using cached wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n","Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from allennlp<2.11,>=2.10.1->allennlp-models) (0.3.6)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp-models) (2022.10.31)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp-models) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.5->allennlp-models) (1.2.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.13.0,>=1.7.0->allennlp-models) (4.4.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (3.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (21.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (10.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (4.13.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (3.8.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (6.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (2022.11.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->allennlp-models) (0.70.14)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp-models) (0.2.5)\n","Collecting boto3<2.0,>=1.0\n","  Using cached boto3-1.26.22-py3-none-any.whl (132 kB)\n","Collecting google-cloud-storage<3.0,>=1.32.0\n","  Using cached google_cloud_storage-2.6.0-py2.py3-none-any.whl (105 kB)\n","Collecting huggingface-hub>=0.0.16\n","  Using cached huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","Collecting rich<13.0,>=12.1\n","  Using cached rich-12.6.0-py3-none-any.whl (237 kB)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (6.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (22.1.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (1.8.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->allennlp-models) (2.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->allennlp-models) (3.0.9)\n","Collecting iniconfig\n","  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n","Collecting pluggy<2.0,>=0.12\n","  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n","Collecting exceptiongroup>=1.0.0rc8\n","  Using cached exceptiongroup-1.0.4-py3-none-any.whl (14 kB)\n","Collecting tomli>=1.0.0\n","  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->allennlp-models) (3.11.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp<2.11,>=2.10.1->allennlp-models) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.28->allennlp<2.11,>=2.10.1->allennlp-models) (2.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28->allennlp<2.11,>=2.10.1->allennlp-models) (1.26.13)\n","Collecting threadpoolctl>=2.0.0\n","  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n","Collecting thinc<8.1.0,>=8.0.14\n","  Using cached thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","Collecting typer>=0.4.1\n","  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n","Collecting spacy-legacy<3.1.0,>=3.0.9\n","  Using cached spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n","Collecting pathy>=0.3.5\n","  Using cached pathy-0.10.0-py3-none-any.whl (48 kB)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n","Collecting jinja2\n","  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n","Collecting cymem<2.1.0,>=2.0.2\n","  Using cached cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n","Collecting typing-extensions\n","  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Collecting srsly<3.0.0,>=2.4.3\n","  Using cached srsly-2.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n","Collecting catalogue<2.1.0,>=2.0.6\n","  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp<2.11,>=2.10.1->allennlp-models) (0.10.1)\n","Collecting preshed<3.1.0,>=3.0.2\n","  Using cached preshed-3.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n","Collecting blis<0.8.0,>=0.4.0\n","  Using cached blis-0.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Using cached pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","Collecting spacy-loggers<2.0.0,>=1.0.0\n","  Using cached spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4,>=2.1.0->allennlp<2.11,>=2.10.1->allennlp-models) (65.6.3)\n","Collecting murmurhash<1.1.0,>=0.28.0\n","  Using cached murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n","Collecting pillow!=8.3.*,>=5.3.0\n","  Using cached Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (0.4.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (3.1.29)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (2.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (1.11.1)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (1.16.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (1.0.11)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (5.9.4)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (1.3.2)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (0.1.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->allennlp-models) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->allennlp-models) (2022.6)\n","Collecting botocore<1.30.0,>=1.29.22\n","  Using cached botocore-1.29.22-py3-none-any.whl (10.2 MB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","Collecting jmespath<2.0.0,>=0.7.1\n","  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (4.0.10)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp<2.11,>=2.10.1->allennlp-models) (2.15.0)\n","Collecting google-resumable-media>=2.3.2\n","  Using cached google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n","Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n","  Using cached google_api_core-2.11.0-py3-none-any.whl (120 kB)\n","Collecting google-cloud-core<3.0dev,>=2.3.0\n","  Using cached google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n","Collecting smart-open<6.0.0,>=5.2.1\n","  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","Collecting pygments<3.0.0,>=2.6.0\n","  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp<2.11,>=2.10.1->allennlp-models) (2.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp<2.11,>=2.10.1->allennlp-models) (5.0.0)\n","Collecting googleapis-common-protos<2.0dev,>=1.56.2\n","  Using cached googleapis_common_protos-1.57.0-py2.py3-none-any.whl (217 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp<2.11,>=2.10.1->allennlp-models) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp<2.11,>=2.10.1->allennlp-models) (4.7.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp<2.11,>=2.10.1->allennlp-models) (5.2.0)\n","Collecting google-crc32c<2.0dev,>=1.0\n","  Using cached google_crc32c-1.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp<2.11,>=2.10.1->allennlp-models) (0.4.8)\n","Building wheels for collected packages: jsonnet\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for jsonnet\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for jsonnet\n","Failed to build jsonnet\n","Installing collected packages: tokenizers, jsonnet, iniconfig, cymem, commonmark, typing-extensions, traitlets, tomli, threadpoolctl, tensorboardX, spacy-loggers, spacy-legacy, smart-open, scipy, pygments, pillow, murmurhash, more-itertools, langcodes, jmespath, jinja2, googleapis-common-protos, google-crc32c, ftfy, filelock, exceptiongroup, conllu, blis, base58, torch, scikit-learn, rich, pydantic, preshed, google-resumable-media, catalogue, botocore, torchvision, srsly, s3transfer, pluggy, huggingface-hub, google-api-core, fairscale, wandb, typer, transformers, thinc, pytest, nltk, google-cloud-core, boto3, pathy, google-cloud-storage, spacy, cached-path, allennlp, allennlp-models\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc2\n","    Uninstalling tokenizers-0.8.1rc2:\n","      Successfully uninstalled tokenizers-0.8.1rc2\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for jsonnet\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Running setup.py install for jsonnet ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while trying to install package.\n","\u001b[31m╰─>\u001b[0m jsonnet\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"]}],"source":["if 'colab' in str(get_ipython()):\n","    import google.colab as colab\n","    from IPython.display import clear_output\n","\n","    colab.auth.authenticate_user()\n","    colab.drive.mount('/content/gdrive') # mount google drive\n","\n","    !pip install tensorflow-text\n","    !pip install transformers==3.3\n","    !pip install datasets\n","    !pip install tqdm\n","    !pip install gsutil\n","    !pip install --upgrade wandb\n","    !pip install --pre allennlp-models\n","\n","    # clear_output()"]},{"cell_type":"code","source":["!apt-get install python3-pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNHZvZWHTAZd","executionInfo":{"status":"ok","timestamp":1670231950985,"user_tz":300,"elapsed":2211,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"251c14f2-5562-45ef-a042-dfbbc960b7b9"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.5).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n"]}]},{"cell_type":"code","source":["!ls /usr/local/bin/ | grep pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTN7aWm9SxPR","executionInfo":{"status":"ok","timestamp":1670231701613,"user_tz":300,"elapsed":335,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"81a7aa52-f778-43df-cf4a-1691c017e68f"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["pip\n","pip3\n","pip3.8\n","pip-compile\n","pip-sync\n"]}]},{"cell_type":"code","source":["# !python3 -m pip freeze | grep transformers\n","# !python3 -m pip freeze | grep tensorflow-text\n","!pip freeze | grep tensorflow-text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNQgGbc9SiaG","executionInfo":{"status":"ok","timestamp":1670237535269,"user_tz":300,"elapsed":818,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"9fa62709-69d0-4c9f-a09b-1b759695a680"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow-text==2.11.0\n"]}]},{"cell_type":"code","source":["# !python3 -V\n","print(sys.version)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKZIXZd61pPR","executionInfo":{"status":"ok","timestamp":1670237538583,"user_tz":300,"elapsed":316,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"b66b3d96-e02e-4d38-e8fa-01bb3e4022df"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["3.8.15 (default, Oct 12 2022, 19:14:39) \n","[GCC 7.5.0]\n"]}]},{"cell_type":"code","source":["!python3 -c \"from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cH8C1nT4hAG","executionInfo":{"status":"ok","timestamp":1670237085371,"user_tz":300,"elapsed":43772,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"6102b075-25c7-45c3-b1bb-83e520360dd0"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","2022-12-05 10:44:04.780997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-05 10:44:04.781294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-05 10:44:04.781328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Downloading: 100% 629/629 [00:00<00:00, 401kB/s]\n","Downloading: 100% 232k/232k [00:00<00:00, 255kB/s]\n","Downloading: 100% 230/230 [00:00<00:00, 132kB/s]\n","Downloading: 100% 268M/268M [00:16<00:00, 16.6MB/s]\n","2022-12-05 10:44:39.422519: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","All model checkpoint weights were used when initializing TFDistilBertForSequenceClassification.\n","\n","All the weights of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n","[{'label': 'POSITIVE', 'score': 0.9998704791069031}]\n"]}]},{"cell_type":"code","source":["!pip show tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnIUzV7F5ftD","executionInfo":{"status":"ok","timestamp":1670237546051,"user_tz":300,"elapsed":1535,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"4878ad40-e161-411b-b43b-4009dc005ace"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tensorflow\n","Version: 2.11.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n","Required-by: tensorflow-text\n"]}]},{"cell_type":"code","source":["!pip show transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMxd0Szu5YUE","executionInfo":{"status":"ok","timestamp":1670237551566,"user_tz":300,"elapsed":2057,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}},"outputId":"bb9aa711-e17c-49f1-d73a-c0867c8fb166"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: transformers\n","Version: 3.3.0\n","Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\n","Home-page: https://github.com/huggingface/transformers\n","Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Patrick von Platen, Sylvain Gugger, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\n","Author-email: thomas@huggingface.co\n","License: Apache\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: filelock, numpy, packaging, regex, requests, sacremoses, sentencepiece, tokenizers, tqdm\n","Required-by: \n"]}]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"7IQfnAOUTleu","outputId":"6c3ef687-0337-4163-a87d-9a798ee6eff0","executionInfo":{"status":"error","timestamp":1670237570270,"user_tz":300,"elapsed":457,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["3.8.15 (default, Oct 12 2022, 19:14:39) \n","[GCC 7.5.0]\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-f1a89476f5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;31m# https://huggingface.co/docs/datasets/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# ml libraries\n","from __future__ import print_function\n","import sys\n","print(sys.version)\n","import tensorflow as tf\n","# import tensorflow_text as tf_text\n","import tensorflow.keras as keras\n","import tensorflow.keras.backend as K\n","import tensorflow_datasets as tfds\n","import transformers\n","import datasets # https://huggingface.co/docs/datasets/\n","\n","# for allennlp, if you did a pip install on colab, restart the runtime\n","# from allennlp.common.testing import (\n","#                                 AllenNlpTestCase,\n","#                                 global_distributed_metric,\n","#                                 run_distributed_test)\n","# from allennlp_models.rc.metrics import DropEmAndF1\n","\n","# data processing libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","# from tqdm.auto import tqdm\n","from google.cloud import storage as gcs\n","\n","# other libraries\n","import os\n","import json\n","import functools\n","import time\n","import math\n","import warnings\n","import string\n","import re\n","import argparse\n","import pickle\n","from collections import Counter\n","from datetime import datetime\n","from IPython.display import clear_output\n","\n","# plot libs\n","import matplotlib.pyplot as plt\n","\n","print(f'TensorFlow {tf.__version__}')"]},{"cell_type":"code","source":["pip freeze | grep transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVVjfWpRxt4o","outputId":"28d0f7dc-cfa4-495e-a2e4-d57106935d97","executionInfo":{"status":"ok","timestamp":1670236580662,"user_tz":300,"elapsed":1703,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"}}},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["transformers==3.3.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A8Cue-K52LC-","colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["a18c218a59854ecda85ffb1a5584e89d","85409ac5f54e455fb49b93d2afec3715","0e7158519aa44bcd898635d4a21d8575","de1515522cd24f5ea74479da1dbb81ba","55317103e2624731b795132ea782f43e","e8e7745fd2b244c2a50022a10caf6e53","6252d0f979aa4be7a916fa5186e9d0a1","b9f6c18783254c80b3e34bcd3bea250c","fece64aaa7b14879bf0d4b6c4d147280","e303ff02b5794fecb4cc54381173517a","646f023ce1b24eb4a3129248b7fadd67","acd2846d34da4557b1de2f54068ab580","0e55c3e2c7b34d8d96968f16a7b35f5c","6ab210b8ea5c4a1b8215ff3ff5d7dcfd","56cbda9f17114224a5ae04d0c785a27d","84aa1d35e5ec45519a003938c1c4710d","c7dbd6bcd50a4e68abb0ec351ce51eb0","b1290391d22141909586326bf121618b","f4ac285af773447fa1a613da3099250f","8bb1e9b09b95452b9efcb5bc9b2ad53a","435db3f76a7344eba1463d4abec2b590","b35598cbe182416c8267c551206656f3","0343e71dd24a4adf92d0a5faa85aad3e","04678d348f8e4de68e566061ea42c616","d291b16651064d86b9a5531cfabd8c9c","a602011ec4e84ee496a7ecb41136153c","4334edf740884cdd83c095ef903c659f","83e70fce3c7741c38d8402c3c4e69c4b","840b8708ee7344db93b3aaa800e3ccb4","80967c65644145efbf4a8cb341e658dd","ba3c566d437f4bdf84baf0911f7e31c0","421ed0a2a9884eaf87170cd2db96620f","4f76b379999c417a8deb933e20ae60f4"]},"outputId":"a0e5755c-3ce5-4c16-9846-9267372f0dee"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a18c218a59854ecda85ffb1a5584e89d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd2846d34da4557b1de2f54068ab580"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0343e71dd24a4adf92d0a5faa85aad3e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}],"source":["PROCESSOR = 'GPU'\n","EVALUATE_DEV = True\n","EVALUATE_TEST = False\n","\n","# ------------------------------------------------------------------------------\n","# SEMSITIVE PRIVATE INFO\n","\n","# path to repo on gdrive\n","# gdrive is used to save/load csv (e.g. performance evaluation reports) and model files \n","GDRIVE_REPO_PATH='/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5'\n","\n","\n","# gcp storage paths\n","DROP_PATH_GCP = '/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5'\n","\n","# token for wandb, training results tracker\n","# WAND_LOGIN_TOKEN = ''\n","\n","# ------------------------------------------------------------------------------\n","# T5 NONSTOP TRAINING CONFIGS\n","\n","# \"t5-small\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json\"\n","# \"t5-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json\"\n","# \"t5-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-large-config.json\"\n","# \"t5-3b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-3b-config.json\"\n","# \"t5-11b\": \"https://s3.amazonaws.com/models.huggingface.co/bert/t5-11b-config.json\"\n","T5_MODEL = 't5-small'\n","# EPOCHS = 2\n","\n","# ------------------------------------------------------------------------------\n","# T5 CONTINUOUS TRAINING CONFIGS\n","# NOTE: Do NOT confuse \"continuous training\" with \"stage training.\" \"Continuous \n","# training\" in this notebook refers to the scenarion where the full traning schedule \n","# (e.g. 60 epochs) for the SAME dataset is broken in to multiple sub trainng schedules \n","# (e.g. two 30-epochs training). \"Stage training\" refers to a new training schedule\n","# thatfor a new dataset, although the training can be on top of a model that has been\n","# trained on other datasets. For example, each stage of the following training schedule\n","# is a stage: NUMERICAL DATASET -> TEXTUAL DATASET -> SQUAD -> DROP. \"Continous\n","# training\" can take place when the 60-epoch training schedule on NUMERICAL DATASET is \n","# broken into two 30-epoch training schedules.\n","\n","# doit: set to true ONLY IF continue training for the SAME dataset\n","# epoch_total defines the total number of epochs for the entire training schedule\n","# epoch_start defines the starting # of epoch for the current training\n","# epoch_end defines the ending # of epoch for the current training\n","# EPOCHS_CONTINUE = {'doit': False, \n","#                    'epoch_total': 60,\n","#                    'epoch_start': 16,\n","#                    'epoch_end': 30}\n","\n","# ------------------------------------------------------------------------------\n","# DATASET CONFIGS\n","\n","# # MUSIQUE DATASET\n","# MUSIQUE_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'musique/musique_train.tfrecord')\n","# MUSIQUE_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'musique/musique_dev.tfrecord')\n","# MUSIQUE_TRAIN_EXAMPLE_COUNT = 39876\n","MUSIQUE_DEV_EXAMPLE_COUNT = 4834\n","# MUSIQUE_TRAIN_JSON = os.path.join(DROP_PATH_GCP, 'musique/musique_train.json')\n","MUSIQUE_DEV_JSON = os.path.join(DROP_PATH_GCP, 'musique_evaluation/musique_full_dev.json')\n","\n","# # DROP DATASET  \n","# DROP_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_train_v4_77400.tfrecord')\n","# DROP_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev_v4_9536.tfrecord')\n","# DROP_TRAIN_EXAMPLE_COUNT = 77400\n","# DROP_DEV_EXAMPLE_COUNT = 9536\n","# DROP_DEV_JSON = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev.json')\n","# DROP_TEST_JSON = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_test_questions.json')\n","\n","# # DROP CATEGORY DATASET\n","# DROP_CATEGORY_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_train_v4_cat_77400.tfrecord')\n","# DROP_CATEGORY_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'drop/drop_dataset_dev_v4_cat_9536.tfrecord')\n","# DROP_CATEGORY_TRAIN_EXAMPLE_COUNT = 77400\n","# DROP_CATEGORY_DEV_EXAMPLE_COUNT = 9536\n","\n","# # NUMERICAL DATASET\n","# SYN_NUM_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'numeric/numeric_train_data_parsed_v2_990000.tfrecord')\n","# SYN_NUM_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'numeric/numeric_dev_data_parsed_v2_9996.tfrecord')\n","# SYN_NUM_TRAIN_EXAMPLE_COUNT = 990000\n","# SYN_NUM_DEV_EXAMPLE_COUNT = 9996\n","\n","# SQUAD_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'squad/squad1.1_train_data_parsed_v3_87599.tfrecord')\n","# SQUAD_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'squad/squad1.1_dev_data_parsed_v3_10570.tfrecord')\n","# SQUAD_TRAIN_EXAMPLE_COUNT = 87599\n","# SQUAD_DEV_EXAMPLE_COUNT = 10570\n","\n","# # TEXTUAL DATASET\n","# SYN_TXT_TRAIN_TFREC = os.path.join(DROP_PATH_GCP, 'textual/textual_train_data_parsed_v2_2523192.tfrecord')\n","# SYN_TXT_DEV_TFREC = os.path.join(DROP_PATH_GCP, 'textual/textual_dev_data_parsed_v2_10000.tfrecord')\n","# SYN_TXT_TRAIN_EXAMPLE_COUNT = 2523192\n","# SYN_TXT_DEV_EXAMPLE_COUNT = 10000\n","\n","# # ------------------------------------------------------------------------------\n","# # TRAINING CONFIGS\n","\n","# # BASIC SETUP\n","BATCH_SIZE = 32\n","ENCODER_MAX_LEN = 512 # must be consistent with configs used to build TFRecords\n","DECODER_MAX_LEN = 54 # must be consistent with configs used to build TFRecords\n","TOKENIZER = transformers.AutoTokenizer.from_pretrained(T5_MODEL)\n","# special_tokens_dict = {'additional_special_tokens': ['0','1','2','3', '4', '5', '6', '7', '8', '9', '<ss>', '<sv>']}\n","# num_added_toks = TOKENIZER.add_special_tokens(special_tokens_dict)\n","\n","# # DATASET MIXTURE CONFIGS\n","# IS_TRAIN_DS_MIXTURE = False\n","# MIXTURE_TEMP = 1\n","# MIXTURE_MAX = None\n","# MIXTURE_SCALE = 1\n","\n","# # TRAINING STEPS\n","# if IS_TRAIN_DS_MIXTURE:\n","#     # mixture\n","#     VALID_TOTAL_EXAMPLE_COUNT = SYN_TXT_DEV_EXAMPLE_COUNT\n","#     VALID_STEPS = math.ceil(VALID_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)\n","#     TRAIN_STEPS = None # train steps will be updated after ds is loaded with the predefined tempature\n","# else:\n","#     # single ds\n","#     TRAIN_TOTAL_EXAMPLE_COUNT = DROP_TRAIN_EXAMPLE_COUNT\n","#     VALID_TOTAL_EXAMPLE_COUNT = DROP_DEV_EXAMPLE_COUNT\n","#     TRAIN_STEPS = math.ceil(TRAIN_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)\n","#     VALID_STEPS = math.ceil(VALID_TOTAL_EXAMPLE_COUNT / BATCH_SIZE)    \n","\n","# # ------------------------------------------------------------------------------\n","# # LARNING RATE CONFIGS\n","\n","# LR_DO_WARMUP_DECAY = True\n","# LR_CONSTANT = 0.001 # constant lr will be used if LR_DO_WARMUP_DECAY is set to False\n","# LR_WARMUP_START = 1e-8 # lr for the 1st epoch\n","# LR_WARMUP_END = 1e-4\n","# LR_MIN = LR_WARMUP_START\n","# LR_DECAY_RATE_LINEAR = 0.001\n","# if EPOCHS >= 10:\n","#     # allocate 10% of training steps to warmup\n","#     WARMP_UP_EPOCHS = EPOCHS / 10 \n","# else:\n","#     # just for testing\n","#     WARMP_UP_EPOCHS = 1\n","\n","# # ------------------------------------------------------------------------------\n","# # MODEL SAVING CONFIGS\n","\n","# SAVE_TRAINED_MODEL = True\n","\n","# SAVE_MODEL_WEIGHTS_ONLY = True\n","# SAVE_MODEL_CHECKPOINTS_LOCAL = True\n","# SAVE_MODEL_CHECKPOINTS_WANDB = False\n","# SAVE_BEST_MODEL_ONLY = True\n","# TENSORBOARD_LOG_PATH = f'{GDRIVE_REPO_PATH}/logs' # must be GCP bucket if the model is running on TPU\n","# MODEL_SAVE_PATH = f'{GDRIVE_REPO_PATH}/models'\n","# SHOW_TENSORBOARD = False\n","# SHOW_WANDB = False\n","# WANDB_PROJECT_NAME = 't5-numerical-reasoning'\n","\n","# # ------------------------------------------------------------------------------\n","# # TRAINING RESULTS TRACKER CONFIGS\n","\n","# if SHOW_WANDB:\n","#     !wandb login $WAND_LOGIN_TOKEN  \n","# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","# plt.style.use('ggplot')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKp4tsQP2zjp","outputId":"d9758ac2-48da-4f3e-8d95-6b866596f16e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using default strategy for CPU/GPU...\n","1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["# ref: https://www.tensorflow.org/guide/tpu\n","if PROCESSOR == \"TPU\":\n","    print(\"connecting to TPU...\")\n","    try:\n","        # 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU: ', tpu.get_master())\n","    except ValueError:\n","        print(\"Error: Unable to connect to TPU...\")\n","        tpu = None\n","\n","    if tpu:\n","        try:\n","            print(\"Initializing TPU...\")\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.TPUStrategy(tpu) # tf 2.3.x\n","            print(\"TPU initialized!\")\n","        except:\n","            print(\"Error: Failed to initialize TPU...\")\n","    else:\n","        PROCESSOR = \"GPU\"\n","\n","if PROCESSOR != \"TPU\":\n","    print(\"Using default strategy for CPU/GPU...\")\n","    strategy = tf.distribute.get_strategy()\n","\n","if PROCESSOR == \"GPU\":\n","    # ref: https://tinyurl.com/yxddsxxq\n","    gpus = tf.config.experimental.list_physical_devices('GPU')\n","    if gpus:\n","        try:\n","            # memory growth needs to be the same across GPUs\n","            for gpu in gpus:\n","                tf.config.experimental.set_memory_growth(gpu, True)\n","            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","        except RuntimeError as e:\n","            # memory growth must be set before GPUs have been initialized\n","            print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELCG2elfHd99","cellView":"form"},"outputs":[],"source":["#@title DropPerformanceMeasure\n","class DropPerformanceMeasure:\n","    def __init__(self, tokenizer: transformers.PreTrainedTokenizer) -> None:\n","        self.__metric = DropEmAndF1()\n","        self.__parsed_examples = []\n","        self.__tokenizer = tokenizer\n","        self.__preds = {}\n","        self.__time = datetime.utcnow().strftime(f'%m%d%H%M%S')\n","        self.__csv_save_path= ''\n","\n","    def load_parse_drop_json_for_eval(\n","                    self,\n","                    json_url: str = MUSIQUE_DEV_JSON, \n","                    example_count: int = MUSIQUE_DEV_EXAMPLE_COUNT,\n","                    test_mode: bool = False) -> int:\n","        \"\"\" Parse Drop json and reconstruct the DROP dataset. \n","        Returns:\n","            (int) Total number of examples parsed.\n","        \"\"\"\n","        with open(json_url) as f:\n","            drop_dict = json.load(f)\n","\n","            # examples = []\n","            input_ids                  = []\n","            attention_masks            = []\n","            answer_types               = []\n","            answer_dicts               = []\n","            validated_answers_dicts    = []\n","            query_ids                  = []\n","            print(f'Parsing \"{json_url}\"...')\n","            with tqdm(total=example_count) as pbar:\n","                for key, json_example in drop_dict.items():\n","                    context = json_example['passage']\n","                    for qa_dict in json_example['qa_pairs']:\n","                        question = qa_dict['question']\n","                        answer = qa_dict['answer']\n","                        _, answer_type = self.__parse_answer(qa_dict['answer'])\n","                        query_id = qa_dict['query_id']\n","                        if 'validated_answers' in qa_dict:\n","                            validated_answers = qa_dict['validated_answers']\n","                        else:\n","                            validated_answers = None\n","                        if answer is None:\n","                            print(f'Skip {query_id} due to None answer...')\n","                            continue\n","\n","                        input_text = f\"answer_me: {question} context: {context}\"\n","                        encoded_query = self.__tokenizer(\n","                                                    input_text, \n","                                                    return_tensors='tf', \n","                                                    padding='max_length', \n","                                                    truncation=True, \n","                                                    max_length=ENCODER_MAX_LEN)\n","\n","                        input_ids.append(encoded_query[\"input_ids\"][0])                  \n","                        attention_masks.append(encoded_query[\"attention_mask\"][0])            \n","                        answer_types.append(answer_type)               \n","                        answer_dicts.append(answer)               \n","                        validated_answers_dicts.append(validated_answers)    \n","                        query_ids.append(query_id)                  \n","\n","                        pbar.update(1)\n","\n","                        if test_mode:\n","                            # parse only one passge & its questions\n","                            break\n","        \n","        self.__parsed_examples = {\n","                'input_ids'                 : input_ids,\n","                'attention_mask'            : attention_masks,\n","                'answer_type'               : answer_types,\n","                'answer_dict'               : answer_dicts,\n","                'validated_answers_dict'    : validated_answers_dicts,\n","                'query_id'                  : query_ids\n","        }\n","\n","        return len(input_ids)\n","\n","    def __parse_answer(\n","                    self, \n","                    answer_dict: dict, \n","                    spans_sep_token: str = '<ss>') -> str:\n","        \"\"\"Parse the answer json node to string. Spans answers will be seperated \n","        using spans_sep_token.\n","        \"\"\"\n","        number = answer_dict['number'].strip()\n","        if number:\n","            return number, 'n'\n","        \n","        spans = answer_dict['spans']\n","        spans_str = spans_sep_token.join([span.strip() for span in spans if span.strip()])\n","        if spans_str:\n","            if len(spans) > 1:\n","                return spans_str, 's'\n","            else:\n","                return spans_str, 'ss'\n","        \n","        date = answer_dict['date']\n","        if len(date) != 3:\n","            return None, None\n","        date = ' '.join([d.strip() for d in [date['day'], date['month'], date['year']] if d.strip()])\n","        if date:\n","            return date, 'd'\n","        \n","        return None, None\n","    \n","    def __parse_validated_answers(\n","                        self, \n","                        validated_answers: list, \n","                        sep_token: str = '<sv>') -> str:\n","        \"\"\"Parse validated_answers json node to string using sep_token.\n","        \"\"\"\n","        if validated_answers is None:\n","            return ''\n","\n","        answers = []\n","        for answer_dict in validated_answers:\n","            ans, _ = self.__parse_answer(answer_dict)\n","            answers.append(ans)\n","        return sep_token.join([a.strip() for a in answers if a.strip()])\n","\n","    def __to_tf_dataset(\n","            self,\n","            parsed_examples: dict, \n","            max_len: int = 512,\n","            batch_size: int = BATCH_SIZE,\n","            test_reduce_data: bool = False) -> tf.data.Dataset:\n","        # convert to hugging face ds\n","        ds = datasets.Dataset.from_dict(parsed_examples)\n","        if test_reduce_data:\n","            test_ds = datasets.Dataset.from_dict(test_ds[:10])\n","            test_quids = test_quids[:10]\n","        \n","        # convert to tf ds\n","        columns = [\n","                'input_ids', \n","                'attention_mask']\n","        ds.set_format(type='tensorflow', columns=columns)\n","        ds_tf = {x: ds[x]\n","                        for x in [\n","                            'input_ids', \n","                            'attention_mask']}        \n","        ds_tf = tf.data.Dataset.from_tensor_slices(ds_tf)\n","        ds_tf = ds_tf.repeat(1)\n","        ds_tf = ds_tf.batch(batch_size)\n","        ds_tf = ds_tf.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","        return ds_tf\n","\n","    def predict(\n","            self,\n","            model: transformers.TFT5ForConditionalGeneration, \n","            ds_example_count: int = 0,\n","            decoder_max_len: int = DECODER_MAX_LEN,\n","            batch_size: int = BATCH_SIZE,\n","            dry_run: bool = False) -> dict:\n","        \"\"\"Predict and decode using the trained T5 model.\n","        Refs:\n","            https://tinyurl.com/yxlr4jmb\n","            https://tinyurl.com/y53l7vfm\n","        Returns:\n","            (tuple) (preds, labels, types)\n","        \"\"\"\n","        if len(self.__parsed_examples) == 0:\n","            return None\n","        \n","        def fix_output_spacing(s: str) -> str:\n","            \"\"\"Fixing the odd bug that numerical numbers are losing a whitespace in \n","            front after adding digits to special tokens.\n","            \"\"\"\n","            match = re.compile(r'([a-z]|,|-)(\\d)')\n","            s = re.sub(match, r'\\1 \\2', s)\n","            match = re.compile(r'(\\d|[a-z])( )?(-)( )?(\\d|[a-z])')\n","            s = re.sub(match, r'\\1\\3\\5', s)\n","            return s\n","\n","        ds = self.__to_tf_dataset(self.__parsed_examples, batch_size=batch_size)        \n","        with tqdm(total=ds_example_count) as pbar:\n","            inputs, preds = [], []\n","            for batch in ds:\n","                outs_pred = model.generate(\n","                                input_ids=batch['input_ids'], \n","                                attention_mask=batch['attention_mask'],\n","                                max_length=decoder_max_len)\n","                \n","                # detokenize and fix the output whitespace bug in front of numbers\n","                outs_pred = [fix_output_spacing(self.__tokenizer.decode(ids))\n","                             for ids in outs_pred]\n","                preds.extend(outs_pred)\n","\n","                # inputs\n","                ins = batch['input_ids']\n","                ins = [self.__tokenizer.decode(input) for input in ins]\n","                inputs.extend(ins)\n","\n","                # update progress bar\n","                pbar.update(len(batch['input_ids']))\n","                if dry_run:\n","                    # process only one batch if dry run\n","                    break\n","                    \n","        self.__preds['inputs'] = inputs\n","        self.__preds['predictions'] = preds\n","        self.__preds['answer_dict'] = self.__parsed_examples['answer_dict']\n","        self.__preds['answer_type'] = self.__parsed_examples['answer_type']\n","        self.__preds['query_id'] = self.__parsed_examples['query_id']\n","        self.__preds['validated_answers_dict'] = self.__parsed_examples['validated_answers_dict']\n","\n","        return self.__preds\n","\n","    def evaluate(\n","            self, \n","            query_id: list,\n","            answer_dict: list,\n","            validated_answers_dict: list,\n","            answer_type: list,\n","            predictions: list,\n","            prediction_spans_sep_token: str = '<ss>',\n","            print_reports: bool = True) -> tuple:\n","        \"\"\"Evaluate a batch.\n","        Refs:\n","            https://tinyurl.com/yyuuvc5b\n","            https://tinyurl.com/y6rmrp85\n","        \"\"\"\n","        metric_overall = DropEmAndF1()\n","        errors = []\n","        for qid, ans, ans_validated, ans_type, pred in zip(\n","                                                query_id,\n","                                                answer_dict, \n","                                                validated_answers_dict,\n","                                                answer_type,\n","                                                predictions):\n","            # build predction for evaluation\n","            if ans_type == 's': # spans answer\n","                prediction_parsed = pred.split(prediction_spans_sep_token)\n","            else:\n","                prediction_parsed = pred\n","\n","            # build truths for evaluation\n","            ground_truths = [ans]\n","            if ans_validated is not None:\n","                ground_truths.extend(ans_validated)\n","            \n","            # track performance per example\n","            metric_example = DropEmAndF1()\n","            metric_example(prediction=prediction_parsed, ground_truths=ground_truths)\n","            example_exact_match, exampe_f1_score = metric_example.get_metric()\n","            \n","            ans_parsed, _ = self.__parse_answer(ans)\n","            ans_val = self.__parse_validated_answers(ans_validated)\n","            \n","            # add to error report\n","            if exampe_f1_score < 1:\n","                example_error = {\n","                        'query_id'          : qid,\n","                        'prediction'        : pred,\n","                        'answer'            : ans_parsed,\n","                        'validated_answers' : ans_val,\n","                        'f1'                : exampe_f1_score,\n","                        'exact_match'       : example_exact_match\n","                }\n","                errors.append(example_error)\n","\n","            # update metrics\n","            metric_overall(prediction=prediction_parsed, ground_truths=ground_truths)\n","\n","        exact_match, f1_score = metric_overall.get_metric()\n","        return exact_match, f1_score, errors\n","    \n","    def evaluate_by_type(\n","                    self, \n","                    prediction_spans_sep_token: str = '<ss>',\n","                    print_reports: bool = True,\n","                    error_print_count: int = 100,\n","                    save_dir: str = None) -> tuple:\n","        \"\"\"Evaluate the performance by question type.\n","        \"\"\"\n","        predictions     = np.array(self.__preds['predictions'])\n","        types           = np.array(self.__preds['answer_type'])\n","        qids            = np.array(self.__preds['query_id'])\n","        inputs          = np.array(self.__preds['inputs'])\n","        answer_dict     = np.array(self.__preds['answer_dict'])\n","        vals            = np.array(self.__preds['validated_answers_dict'])\n","        \n","        types   = types.reshape(types.shape[0])\n","        qids    = qids.reshape(qids.shape[0])\n","        inputs  = inputs.reshape(inputs.shape[0])\n","\n","        types_n     = types=='n'\n","        types_d     = types=='d'\n","        types_ss    = types=='ss'\n","        types_s     = types=='s'\n","\n","        types_n     = types_n.reshape(types_n.shape[0])\n","        types_d     = types_d.reshape(types_d.shape[0])\n","        types_ss    = types_ss.reshape(types_ss.shape[0])\n","        types_s     = types_s.reshape(types_s.shape[0])\n","\n","        number_eval = self.evaluate(\n","                        qids[types_n].tolist(),\n","                        answer_dict[types_n].tolist(),\n","                        vals[types_n].tolist(),\n","                        types[types_n].tolist(),\n","                        predictions[types_n].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","\n","        date_eval = self.evaluate(\n","                        qids[types_d].tolist(),\n","                        answer_dict[types_d].tolist(),\n","                        vals[types_d].tolist(),\n","                        types[types_d].tolist(),\n","                        predictions[types_d].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        span_eval = self.evaluate(\n","                        qids[types_ss].tolist(),\n","                        answer_dict[types_ss].tolist(),\n","                        vals[types_ss].tolist(),\n","                        types[types_ss].tolist(),\n","                        predictions[types_ss].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        spans_eval = self.evaluate(\n","                        qids[types_s].tolist(),\n","                        answer_dict[types_s].tolist(),\n","                        vals[types_s].tolist(),\n","                        types[types_s].tolist(),\n","                        predictions[types_s].tolist(),\n","                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        \n","        evals_cat = {\n","            'number'    : {'exact_match': number_eval[0], 'f1': number_eval[1]},\n","            'date'      : {'exact_match': date_eval[0], 'f1': date_eval[1]},\n","            'span'      : {'exact_match': span_eval[0], 'f1': span_eval[1]},\n","            'spans'     : {'exact_match': spans_eval[0], 'f1': spans_eval[1]}\n","        }\n","        errors_cat = {\n","            'number'    : number_eval[2],\n","            'date'      : date_eval[2],\n","            'sapn'      : span_eval[2],\n","            'spans'     : spans_eval[2]\n","        }\n","\n","        # generate reports\n","        print('\\n\\n')\n","        print('CATEGORY PERFORMANCE')\n","        df_cat = pd.DataFrame(evals_cat)\n","        display(df_cat)\n","\n","        print('\\n\\n')\n","        print('ERROR ANALYSIS')\n","        for item in errors_cat.items():\n","            q_type = item[0]\n","            \n","            # print\n","            print(f'Question Type: {q_type.capitalize()}')\n","            df = pd.DataFrame(item[1])\n","            if df.shape[0] > error_print_count:\n","                df_sample = df.sample(n=error_print_count)\n","            else:\n","                df_sample = df\n","            display(df_sample)\n","            print('\\n')\n","\n","            # save\n","            if save_dir is not None:\n","                path = f'{self.__csv_save_path}/{save_dir}/performace_reports_{self.__time}'\n","            else:\n","                path = f'{self.__csv_save_path}/performace_reports_{self.__time}'\n","            os.makedirs(path, exist_ok=True)\n","            df_cat.to_csv(f'{path}/performance_category.csv')\n","            df_sample.to_csv(f'{path}/ea_{q_type}_sample_{df_sample.shape[0]}.csv')\n","            df.to_csv(f'{path}/ea_{q_type}_full_{df.shape[0]}.csv')\n","        \n","        print(f\"\\nError reports have been saved to {path}!\")\n","\n","        return evals_cat, errors_cat\n","\n","    def __get_errors(\n","                self,\n","                predictions: np.ndarray,\n","                truths: np.ndarray,\n","                qids: np.ndarray,\n","                inputs: np.ndarray) -> dict:\n","        filter_ = predictions != truths\n","        return {\n","            'query_ids': qids[filter_],\n","            'predictions': predictions[filter_], \n","            'truths': truths[filter_],\n","            'inputs': inputs[filter_]}\n","\n","    def evaluate_all(\n","                self, \n","                save_dir: str = None,\n","                prediction_spans_sep_token: str = '<ss>') -> None:\n","        exact_match, f1_score, _ = self.evaluate(\n","                                        self.__preds['query_id'], \n","                                        self.__preds['answer_dict'], \n","                                        self.__preds['validated_answers_dict'],\n","                                        self.__preds['answer_type'],\n","                                        self.__preds['predictions'],\n","                                        prediction_spans_sep_token=prediction_spans_sep_token)\n","        \"\"\"Evaluate the performance across the entire dataset.\n","        \"\"\"\n","        # generate eval report\n","        print('')\n","        print('OVERALL PERFORMANCE')\n","        evals_overall = {'exact_match': exact_match, 'f1': f1_score}\n","        df_overall = pd.DataFrame(evals_overall, index=[0])\n","        display(df_overall.style.hide_index())\n","\n","        # save report\n","        if save_dir is not None:\n","            path = f'{self.__csv_save_path}/{save_dir}/performace_reports_{self.__time}'\n","            \n","        else:\n","            path = f'{self.__csv_save_path}/performace_reports_{self.__time}'\n","        os.makedirs(path, exist_ok=True)\n","        df_overall.to_csv(f'{path}/performance_overall.csv')\n","\n","    def get_eval_reports(\n","                    self, \n","                    csv_save_path: str,\n","                    prediction_spans_sep_token: str = '<ss>',\n","                    print_reports: bool = True,\n","                    grouping_dir: str = None) -> None:\n","        \"\"\"Function to produce the performance evaluation report.\n","        Args:\n","            csv_save_path: Path to the folder where the reports will be saved to.\n","            prediction_spans_sep_token: Token used to separate the different answers for spans.\n","            print_reports: Set true to print sample reports in the notebook.\n","            grouping_dir: Optional; folder to be created under csv_save_path for saving the reports.\n","        \"\"\"\n","        self.__csv_save_path = csv_save_path\n","        self.evaluate_all(\n","                    save_dir=grouping_dir, \n","                    prediction_spans_sep_token=prediction_spans_sep_token)\n","        self.evaluate_by_type(\n","                    save_dir=grouping_dir,\n","                    prediction_spans_sep_token=prediction_spans_sep_token)\n","    \n","    def reset(self) -> None:\n","        self.__metric = DropEmAndF1()\n","        self.__parsed_examples = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SpS-qUAIzkLh","cellView":"form"},"outputs":[],"source":["#@title DROPBaseT5\n","class DROPBaseT5(transformers.TFT5ForConditionalGeneration):\n","    def __init__(self, *args, log_dir: str = None, cache_dir: str = None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.loss_tracker= tf.keras.metrics.Mean(name='loss')\n","\n","    # Notes from doc:\n","    # When you need to customize what fit() does, you should override the training \n","    # step function of the Model class. This is the function that is called by fit() \n","    # for every batch of data. You will then be able to call fit() as usual -- and \n","    # it will be running your own learning algorithm.\n","    @tf.function\n","    def train_step(self, data: datasets.Dataset) -> dict:\n","        # required for eager execution when customzing the the training loops\n","        with tf.GradientTape() as tape:\n","            # forward pass; equivalent of pushing the input x through the entire \n","            # neural network for a prediction\n","            # Note:\n","            # \"self\" is a reference to TFT5ForConditionalGeneration, which is a \n","            # subclass of keras.Model, which returns a reference to a function.\n","            # https://tinyurl.com/yx9qvmyf\n","            # https://keras.io/guides/customizing_what_happens_in_fit/\n","            # https://huggingface.co/transformers/model_doc/t5.html#tft5forconditionalgeneration\n","            # outputs = self(data, training=True) \n","            print(data[\"input_ids\"])\n","            outputs = super().call(\n","                        inputs=data[\"input_ids\"],\n","                        labels=data[\"labels\"],\n","                        attention_mask=data[\"attention_mask\"],\n","                        decoder_attention_mask=data[\"decoder_attention_mask\"],\n","                        training=True)\n","        \n","            # record the gradient\n","            # output of hugging face is a tuple: (outputs.loss, outputs.logits)\n","            # https://huggingface.co/transformers/main_classes/output.html \n","            loss = tf.reduce_mean(outputs[0])\n","            grads = tape.gradient(loss, self.trainable_variables)\n","        \n","        # optimizer as defined through Keras' API when compiling the model\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n","        \n","        # track metrics\n","        y = tf.reshape(data[\"labels\"], [-1, 1])\n","        y_pred_logits = outputs[1]\n","        # lr = self.optimizer._decayed_lr(tf.float32)\n","        self.loss_tracker.update_state(loss)        \n","        self.compiled_metrics.update_state(data[\"labels\"], y_pred_logits)\n","        metrics = {m.name: m.result() for m in self.metrics}\n","        # metrics.update({'lr': lr})\n","        metrics.update({'loss': loss})\n","        \n","        return metrics\n","\n","    @tf.function\n","    def test_step(self, data: datasets.Dataset) -> dict:\n","        outputs = self(data, training=True) \n","        y_pred_logits = outputs[1]\n","        loss = outputs[0]\n","\n","        # compute loss\n","        loss = tf.reduce_mean(loss)\n","        self.loss_tracker.update_state(loss)\n","\n","        # update metrics\n","        y = tf.reshape(data[\"labels\"], [-1, 1])\n","        self.compiled_metrics.update_state(y, y_pred_logits)\n","        metrics = {m.name: m.result() for m in self.metrics}\n","        metrics.update({'loss': loss})\n","\n","        return metrics\n","    \n","    @tf.function\n","    def reset_f1(self) -> dict:\n","        print('Reset F1...')\n","\n","# class LRScheduler(keras.callbacks.Callback):\n","#     \"\"\"Performing custom learning rate scheduling by extending Keras' Callback.\n","#     \"\"\"\n","\n","#     def __init__(\n","#             self, \n","#             warmup_batches      : int = TRAIN_STEPS * WARMP_UP_EPOCHS, \n","#             lr_warmup_start     : float = LR_WARMUP_START, \n","#             lr_warmup_end       : float = LR_WARMUP_END, \n","#             lr_min              : int = LR_MIN,\n","#             decay_rate          : float = LR_DECAY_RATE_LINEAR,\n","#             verbose             : int = 1):\n","#         super(LRScheduler, self).__init__()\n","\n","#         # warm-up\n","#         self.__warmup_batches = warmup_batches\n","#         self.__lr_warmup_start = lr_warmup_start\n","#         self.__lr_warmup_end = lr_warmup_end\n","#         self.__lr_warmup_increment = (self.__lr_warmup_end - self.__lr_warmup_start) / self.__warmup_batches\n","#         self.__is_warmup = True\n","\n","#         # decay\n","#         self.__decay_rate = decay_rate\n","#         self.__lr_min = lr_min\n","\n","#         # other properties\n","#         self.__verbose = verbose\n","#         self.__batch_count = 0\n","#         self.__lr_warmup_arr = [] # by training step\n","#         self.__lr_epoch_arr = [] # by training epoch\n","        \n","#         self.__lr = 0\n","#         self.__epoch = 0\n","#         self.__warmup_epoch_last = 0 # epoch number where warmup ends\n","\n","#     def on_batch_begin(self, batch, logs=None) -> None:\n","#         if self.__is_warmup:\n","#             if self.__batch_count <= self.__warmup_batches: \n","#                 self.__lr = self.__batch_count * self.__lr_warmup_increment + self.__lr_warmup_start\n","#                 K.set_value(self.model.optimizer.lr, self.__lr)\n","#                 self.__lr_warmup_arr.append(self.__lr)\n","#                 self.__batch_count  += 1\n","\n","#                 if self.__verbose > 0:\n","#                     print(f'\\nWarm-up LR {self.__lr} at batch {self.__batch_count}...')                \n","            \n","#     def on_batch_end(self, batch, logs=None) -> None:\n","#         if self.__is_warmup:\n","#             # end of warmup\n","#             if self.__batch_count > self.__warmup_batches: \n","#                 self.__warmup_epoch_last = self.__epoch\n","#                 self.__is_warmup = False\n","\n","#     def on_epoch_begin(self, epoch, logs=None) -> None:\n","#         self.__epoch = epoch\n","#         if self.__is_warmup:\n","#             # hard code the lr calculation because on_batch_end for the first\n","#             # batch of the epoch happens right after on_epoch_begin\n","#             lr = self.__batch_count * self.__lr_warmup_increment + self.__lr_warmup_start    \n","#             self.__lr_epoch_arr.append(lr)\n","#             return\n","        \n","#         self.__lr = K.get_value(self.model.optimizer.lr)\n","#         if self.__lr <= self.__lr_min:\n","#             K.set_value(self.model.optimizer.lr, self.__lr)\n","#             self.__lr_epoch_arr.append(K.get_value(self.model.optimizer.lr))\n","#             return\n","\n","#         lr_new = self.__lr * 1 / (1 + self.__decay_rate * (epoch - self.__warmup_epoch_last))\n","#         K.set_value(self.model.optimizer.lr, lr_new)\n","#         self.__lr = K.get_value(self.model.optimizer.lr) # pull lr from optimizer to confirm\n","#         self.__lr_epoch_arr.append(self.__lr)\n","\n","#     def simulate_lr(\n","#             self, \n","#             steps_simulation: int = 1000,\n","#             steps_per_epoch: int = TRAIN_STEPS,\n","#             plot: bool = True) -> list:\n","#         # hard code a model for simulation\n","#         # note: self.model is accessible through tf in production\n","#         self.model = DROPBaseT5.from_pretrained(T5_MODEL)\n","#         self.model.compile(optimizer=keras.optimizers.Adam())\n","\n","#         # simulate training\n","#         for global_step in range(steps_simulation):\n","#             batch_n = global_step % steps_per_epoch\n","#             if batch_n == 0:\n","#                 self.on_epoch_begin(global_step // steps_per_epoch)\n","#             self.on_batch_begin(batch_n)\n","#             self.on_batch_end(batch_n)\n","\n","#         if plot:\n","#             # plot warmup lr\n","#             x = range(1, len(self.__lr_warmup_arr) + 1)\n","#             print('')\n","#             print(f'Steps per epoch: {steps_per_epoch}')\n","#             fig, ax = plt.subplots(figsize=(15, 6))\n","#             ax.set_title(f'LR Warmup Schedule ({self.__warmup_batches:.0f} warm-up batches)', fontsize=14, pad=11)\n","#             ax.set_ylabel('Learning Rate')\n","#             ax.set_xlabel('Batch Step')\n","#             ax.plot(x, self.__lr_warmup_arr)\n","#             plt.show()\n","\n","#             # plot epoch lr\n","#             x = range(1, len(self.__lr_epoch_arr) + 1)\n","#             print('')\n","#             fig, ax = plt.subplots(figsize=(15, 6))\n","#             ax.set_title(f'LR Epoch Schedule', fontsize=14, pad=11)\n","#             ax.set_ylabel('Learning Rate')\n","#             ax.set_xlabel('Epoch')\n","#             ax.plot(x, self.__lr_epoch_arr)\n","#             print(f'Ending LR: {self.__lr}')\n","#             plt.show()\n","\n","#         return self.__lr_epoch_arr\n","\n","# class LRSimpleScheduler(keras.callbacks.Callback):\n","#     \"\"\"The scheduler takes in a list of learning rates, and feed each learning\n","#     rate to the model at the beginning of an epoch. If the number of epoch is larger\n","#     than the length of the supplied learning rate list, the last item in the list will\n","#     be repeatedly fed to the model.\n","#     \"\"\"\n","#     def __init__(self, learning_rates: list) -> None:\n","#         self.__lr_schedule = learning_rates\n","#         self.__lr_actual = []\n","            \n","#     def on_epoch_begin(self, epoch, logs=None) -> None:\n","#         if epoch < len(self.__lr_schedule):\n","#             K.set_value(self.model.optimizer.lr, self.__lr_schedule[epoch])\n","#         else:\n","#             i_last = len(self.__lr_schedule) - 1\n","#             K.set_value(self.model.optimizer.lr, self.__lr_schedule[i_last])\n","        \n","#         lr = K.get_value(self.model.optimizer.lr)\n","#         self.__lr_actual.append(lr)\n","    \n","#     def simulate_lr(\n","#             self, \n","#             steps_simulation: int,\n","#             steps_per_epoch: int = TRAIN_STEPS) -> list:\n","#         self.model = DROPBaseT5.from_pretrained(T5_MODEL)\n","#         self.model.compile(optimizer=keras.optimizers.Adam())\n","\n","#         # simulate training\n","#         for global_step in range(steps_simulation):\n","#             batch_n = global_step % steps_per_epoch\n","#             if batch_n == 0:\n","#                 self.on_epoch_begin(global_step // steps_per_epoch)\n","#             self.on_batch_begin(batch_n)\n","#             self.on_batch_end(batch_n)\n","\n","#         # plot epoch lr\n","#         x = range(1, len(self.__lr_actual) + 1)\n","#         print('')\n","#         fig, ax = plt.subplots(figsize=(15, 6))\n","#         ax.set_title(f'LR Epoch Schedule', fontsize=14, pad=11)\n","#         ax.set_ylabel('Learning Rate')\n","#         ax.set_xlabel('Epoch')\n","#         ax.plot(x, self.__lr_actual)\n","#         plt.show()\n","\n","#         return self.__lr_actual\n","\n","# def get_continous_training_lr_list(\n","#                             warmup_batches: int,\n","#                             lr_warmup_start: int = LR_WARMUP_START,\n","#                             lr_warmup_end: int = LR_WARMUP_END,\n","#                             lr_min: float = LR_MIN,\n","#                             decay_rate: float = LR_DECAY_RATE_LINEAR,\n","#                             epochs_continue: dict = EPOCHS_CONTINUE,\n","#                             training_steps: int = TRAIN_STEPS) -> list:\n","#     # first, simulate the entire training schedule as if it is nonstop\n","#     total_train_step = epochs_continue['epoch_total'] * TRAIN_STEPS\n","#     lrs = LRScheduler(\n","#                 warmup_batches      = warmup_batches, \n","#                 lr_warmup_start     = lr_warmup_start, \n","#                 lr_warmup_end       = lr_warmup_end, \n","#                 lr_min              = lr_min,\n","#                 decay_rate          = decay_rate,\n","#                 verbose             = 0)\n","#     lr_epochs_simulated = lrs.simulate_lr(total_train_step, TRAIN_STEPS, False)\n","\n","#     # second, extract the learning rates from the simulated epochs \n","#     return lr_epochs_simulated[\n","#                         epochs_continue['epoch_start']-1:\n","#                         epochs_continue['epoch_end']:\n","#                         1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128,"status":"ok","timestamp":1670117997523,"user":{"displayName":"Omkar Kanade","userId":"07956697611657918273"},"user_tz":300},"id":"tByfTuAVKa73","outputId":"b45fceb7-e762-4e96-844d-a1b4fd5432e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["ItemsViewHDF5(<HDF5 file \"model_train_end.h5\" (mode r+)>)\n"]}],"source":["import h5py\n","PRED_MODEL_PATH = f'{GDRIVE_REPO_PATH}/musique_evaluation/musique_model_train_end.h5'\n","f = h5py.File(TRAIN_MODEL_PATH,  \"a\")\n","print(f.items())\n","encoder_weights = f['encoder']\n","decoder_weights = f['decoder']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["018b1eb30edd44f799a2152dc6c79682","8949e0383b9f45c68b2e1038da27a5cd","f222eb5621cf41518d610bd219c923b9","a15b6bd14b32473ab354c1825aa542cf","f1b8ae1710d84b628898a68e8eec45a6","1f47f3f26ab442e89f766e0c7a89d0f1","c5a84c8e41e54835bcc5b4882e9128ed","1ddfb944cf24470d847179a52d3cdaf2","287d98550f854247ba9712ed037a73e6","0ecaa14db5d347f7a89a6e7c99c0ae77","6c8e09601bd24ce38777b1aea050a8fe","0914e701652142da8947fb5ced8fb783","95df437f414b4a51922e52b2461f0b35","3cecaec9073d46caaa8b387cc082bdd4","a03332f4f7174c97bbdd193727b2643d","24410b4e497c4a54b183febca30a4810","be1eadf06a6440cd82e4226e9522366c","ded41c42657c4959aed8fb3cea9c5618","7a2f17e34f0e41f886564a608f173855","8216176500cb46288e6d6f8bf94d10ef","b961ae05ffff4dfb8310e77cef42a2dc","0f4653bca1914e77b533b8a85ff8061c"],"base_uri":"https://localhost:8080/","height":1000},"id":"a96Mnybas_WF","outputId":"cb1c8819-f9dc-48c3-8e4e-67350316b2be"},"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing DROPBaseT5.\n","\n","All the layers of DROPBaseT5 were initialized from the model checkpoint at t5-small.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DROPBaseT5 for predictions without further training.\n","No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n","WARNING:tensorflow:Skipping loading weights for layer #1 (named encoder) due to mismatch in shape for weight drop_base_t5/encoder/block_._0/layer_._0/SelfAttention/relative_attention_bias/embeddings:0. Weight expects shape (32, 8). Received saved weight with shape (512, 512)\n","WARNING:tensorflow:Skipping loading weights for layer #1 (named encoder) due to mismatch in shape for weight drop_base_t5/encoder/block_._0/layer_._0/SelfAttention/o/kernel:0. Weight expects shape (512, 512). Received saved weight with shape (32, 8)\n","WARNING:tensorflow:Skipping loading of weights for layer #2 (named decoder) due to mismatch in number of weights. Layer expects 80 weight(s). Received 81 saved weight(s)\n"]},{"output_type":"stream","name":"stdout","text":["Parsing \"/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/musique_evaluation/musique_full_dev.json\"...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4834 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018b1eb30edd44f799a2152dc6c79682"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Total number of examples to be evaluated: 2417\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4834 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0914e701652142da8947fb5ced8fb783"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","OVERALL PERFORMANCE\n"]},{"output_type":"display_data","data":{"text/plain":["<pandas.io.formats.style.Styler at 0x7fc516465460>"],"text/html":["<style type=\"text/css\">\n","</style>\n","<table id=\"T_e2968_\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th class=\"col_heading level0 col0\" >exact_match</th>\n","      <th class=\"col_heading level0 col1\" >f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td id=\"T_e2968_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n","      <td id=\"T_e2968_row0_col1\" class=\"data row0 col1\" >0.000062</td>\n","    </tr>\n","  </tbody>\n","</table>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","CATEGORY PERFORMANCE\n"]},{"output_type":"display_data","data":{"text/plain":["             number  date      span  spans\n","exact_match       0     0  0.000000      0\n","f1                0     0  0.000062      0"],"text/html":["\n","  <div id=\"df-67c0012a-bac8-4c96-9cd3-acb584ccec45\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>date</th>\n","      <th>span</th>\n","      <th>spans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>exact_match</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>f1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.000062</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67c0012a-bac8-4c96-9cd3-acb584ccec45')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-67c0012a-bac8-4c96-9cd3-acb584ccec45 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-67c0012a-bac8-4c96-9cd3-acb584ccec45');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","ERROR ANALYSIS\n","Question Type: Number\n"]},{"output_type":"display_data","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"],"text/html":["\n","  <div id=\"df-9e0a4d6d-84cc-403e-b97f-8ec6d2cc5a34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e0a4d6d-84cc-403e-b97f-8ec6d2cc5a34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e0a4d6d-84cc-403e-b97f-8ec6d2cc5a34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e0a4d6d-84cc-403e-b97f-8ec6d2cc5a34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Question Type: Date\n"]},{"output_type":"display_data","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"],"text/html":["\n","  <div id=\"df-80e21253-ae63-4d6e-b389-6d2907402f04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80e21253-ae63-4d6e-b389-6d2907402f04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-80e21253-ae63-4d6e-b389-6d2907402f04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-80e21253-ae63-4d6e-b389-6d2907402f04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Question Type: Sapn\n"]},{"output_type":"display_data","data":{"text/plain":["     query_id                                         prediction  \\\n","1304           <pad> aroseroseroseroseroseroseroseroseroseros...   \n","920            <pad> a a a a a a a a a a a a a a a a a a a a ...   \n","2120           <pad> - (projet) - (««««««««««««««««««««««««««...   \n","318            <pad> a???????????????????????????????????????...   \n","37             <pad> a a a a a a a a a a a a a a a a a a a a ...   \n","...       ...                                                ...   \n","2205           <pad> a a a a a a a a a a a a a a a a a a a a ...   \n","381            <pad> a???????????????????????????????????????...   \n","1831           <pad> a???????????????????????????????????????...   \n","2381           <pad>?????????????????????????????????????????...   \n","820            <pad> a???????????????????????????????????????...   \n","\n","                                                 answer  \\\n","1304                                    Karen Fairchild   \n","920                                  Katharina von Bora   \n","2120                                          KUAT-TV 6   \n","318                                                2016   \n","37                                          Steve Irwin   \n","...                                                 ...   \n","2205  a long period of prosperity for the British pe...   \n","381                                         Maria Bello   \n","1831                                                406   \n","2381  its elevation makes it Israel's primary strate...   \n","820                                               Irish   \n","\n","                                      validated_answers   f1  exact_match  \n","1304                                    Karen Fairchild  0.0          0.0  \n","920                                  Katharina von Bora  0.0          0.0  \n","2120                                          KUAT-TV 6  0.0          0.0  \n","318                                                2016  0.0          0.0  \n","37                                          Steve Irwin  0.0          0.0  \n","...                                                 ...  ...          ...  \n","2205  a long period of prosperity for the British pe...  0.0          0.0  \n","381                                         Maria Bello  0.0          0.0  \n","1831                                                406  0.0          0.0  \n","2381  its elevation makes it Israel's primary strate...  0.0          0.0  \n","820                                               Irish  0.0          0.0  \n","\n","[100 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-c7cef924-b255-4a6d-a25b-b038ccdda165\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>prediction</th>\n","      <th>answer</th>\n","      <th>validated_answers</th>\n","      <th>f1</th>\n","      <th>exact_match</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1304</th>\n","      <td></td>\n","      <td>&lt;pad&gt; aroseroseroseroseroseroseroseroseroseros...</td>\n","      <td>Karen Fairchild</td>\n","      <td>Karen Fairchild</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>920</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a a a a a a a a a a a a a a a a a a a a ...</td>\n","      <td>Katharina von Bora</td>\n","      <td>Katharina von Bora</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2120</th>\n","      <td></td>\n","      <td>&lt;pad&gt; - (projet) - (««««««««««««««««««««««««««...</td>\n","      <td>KUAT-TV 6</td>\n","      <td>KUAT-TV 6</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>318</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a???????????????????????????????????????...</td>\n","      <td>2016</td>\n","      <td>2016</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a a a a a a a a a a a a a a a a a a a a ...</td>\n","      <td>Steve Irwin</td>\n","      <td>Steve Irwin</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2205</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a a a a a a a a a a a a a a a a a a a a ...</td>\n","      <td>a long period of prosperity for the British pe...</td>\n","      <td>a long period of prosperity for the British pe...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>381</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a???????????????????????????????????????...</td>\n","      <td>Maria Bello</td>\n","      <td>Maria Bello</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1831</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a???????????????????????????????????????...</td>\n","      <td>406</td>\n","      <td>406</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2381</th>\n","      <td></td>\n","      <td>&lt;pad&gt;?????????????????????????????????????????...</td>\n","      <td>its elevation makes it Israel's primary strate...</td>\n","      <td>its elevation makes it Israel's primary strate...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td></td>\n","      <td>&lt;pad&gt; a???????????????????????????????????????...</td>\n","      <td>Irish</td>\n","      <td>Irish</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7cef924-b255-4a6d-a25b-b038ccdda165')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7cef924-b255-4a6d-a25b-b038ccdda165 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7cef924-b255-4a6d-a25b-b038ccdda165');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","Question Type: Spans\n"]},{"output_type":"display_data","data":{"text/plain":["Empty DataFrame\n","Columns: []\n","Index: []"],"text/html":["\n","  <div id=\"df-f9e916ba-e059-4792-baff-6f12502a10fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e916ba-e059-4792-baff-6f12502a10fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f9e916ba-e059-4792-baff-6f12502a10fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f9e916ba-e059-4792-baff-6f12502a10fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Error reports have been saved to /content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5/musique_evaluation/error_reports//performace_reports_1204070008!\n"]}],"source":["GDRIVE_REPO_PATH='/content/gdrive/Shareddrives/NLP - Op tASk/NLP NRot Improvement/numeric-t5'\n","EVALUATE_DEV = True\n","\n","if EVALUATE_DEV:\n","    PRED_LOAD_MODEL = True\n","    PRED_MODEL = 't5-small'\n","    PRED_MODEL_PATH = f'{GDRIVE_REPO_PATH}/musique_evaluation/musique_model_train_end.h5'\n","    EVAL_REPORT_SAVE_PATH = f'{GDRIVE_REPO_PATH}/musique_evaluation/error_reports/'\n","\n","    if PRED_LOAD_MODEL:\n","        keras.backend.clear_session() \n","        with strategy.scope(): \n","            model_pred = DROPBaseT5.from_pretrained(PRED_MODEL)\n","            model_pred.compile()\n","            model_pred.load_weights(PRED_MODEL_PATH, by_name=True, skip_mismatch=True)\n","    # else:\n","    #     model_pred = model\n","\n","    dev_eval = DropPerformanceMeasure(TOKENIZER)\n","    count = dev_eval.load_parse_drop_json_for_eval(test_mode=False)\n","    print(f'Total number of examples to be evaluated: {count}')\n","    dev_eval.predict(\n","                model=model_pred, \n","                # batch_size=10, # only required if dry_run = True\n","                ds_example_count=MUSIQUE_DEV_EXAMPLE_COUNT,\n","                dry_run=False)\n","    dev_eval.get_eval_reports(\n","                csv_save_path=EVAL_REPORT_SAVE_PATH,\n","                prediction_spans_sep_token='<ss>')"]}]}